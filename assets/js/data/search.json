[ { "title": "Tensor_network_in_quantum_information_science_engineering_physics", "url": "/posts/Tensor_network_in_Quantum_Information_Science_Engineering_Physics/", "categories": "", "tags": "", "date": "2022-11-30 00:00:00 +0700", "snippet": "Unify Quantum Information Science and Quantum Machine Learning with Quantum Tensor Networks as modern diagrammatic reasoning on GPUs ClusterBoring and waiting for NVIDIA cuQuantum appliance for multi-node-multi-gpu for Quantum Tensor Network, we skipped vector state simulation moved to tensor network for quantum circuit simulation. It might be the future for design optimization algorithms and bridging gaps to understand correlated quantum systems more[1][2].Tensor network may be fundamental building block of quantum information processing that connects computer science, condensed matter physics and mathematics[3].With love on classical digital circuit for diagrammatic reasoning, some may be interested in quantum circuit and their graphical language for quantum engineering.Quantum Simulation PennyLane runing on GPUPennyLane Installation indirectly and easy with DockerPennyLane with cuQuantum:Lightning-fast simulations with PennyLane and the NVIDIA cuQuantum SDKBuild from docker:GitHub - PennyLaneAI/pennylane-lightning-gpu: GPU-enabled device for PennyLane$ git clone https://github.com/PennyLaneAI/pennylane-lightning-gpu.git$ cd pennylane-lightning-gpu$ docker build . -f ./docker/Dockerfile -t \"lightning-gpu-wheels\"Successfully tagged lightning-gpu-wheels:latest$ docker run -v `pwd`:/io -it lightning-gpu-wheels cp -r ./wheelhouse /io$ conda create -n pennylane python=3.8$ conda activate pennylaneCheck python version$ python3 --version$ python3 -m pip install ./wheelhouse/PennyLane_Lightning_GPU-0.27.0.dev1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl$ pip install cuquantum$ conda activate quantum-computingBenchmark Jacobian:Lightning-fast simulations with PennyLane and the NVIDIA cuQuantum SDK[4]Verify we can running Quantum Circuit on A100 GPUHaving worked benchmarking quantum computing on GPUs, we learn NVIDIA cuQuantum SDK can applied on PennyLane framework[4].import pennylane as qmlfrom timeit import default_timer as timer# To set the number of threads used when executing this script,# export the OMP_NUM_THREADS environment variable.# Choose number of qubits (wires) and circuit layerswires = 20layers = 3# Set number of runs for timing averagingnum_runs = 5# Instantiate CPU (lightning.qubit) or GPU (lightning.gpu) devicedev = qml.device('lightning.gpu', wires=wires)# Create QNode of device and circuit@qml.qnode(dev, diff_method=\"adjoint\")def circuit(parameters): qml.StronglyEntanglingLayers(weights=parameters, wires=range(wires)) return [qml.expval(qml.PauliZ(i)) for i in range(wires)]# Set trainable parameters for calculating circuit Jacobianshape = qml.StronglyEntanglingLayers.shape(n_layers=layers, n_wires=wires)weights = qml.numpy.random.random(size=shape)# Run, calculate the quantum circuit Jacobian and average the timing resultstiming = []for t in range(num_runs): start = timer() jac = qml.jacobian(circuit)(weights) end = timer() timing.append(end - start)print(qml.numpy.mean(timing))14.54812168199569Simulate Tensor-network on PennyLane framework with CPU!conda install -y matplotlib import pennylane as qmlfrom pennylane import numpy as npdef block(weights, wires): qml.RX(weights[0], wires=wires[0]) qml.RY(weights[1], wires=wires[1]) qml.CNOT(wires=wires)dev = qml.device(\"default.qubit\", wires=4)@qml.qnode(dev)def circuit(template_weights): qml.MPS( wires=range(4), n_block_wires=2, block=block, n_params_block=2, template_weights=template_weights, ) return qml.expval(qml.PauliZ(wires=3))np.random.seed(1)weights = np.random.random(size=[3, 2])qml.drawer.use_style(\"black_white\")fig, ax = qml.draw_mpl(circuit, expansion_strategy=\"device\")(weights)fig.set_size_inches((6, 3))Apply tensor network quantum circuit to classifying the bars and stripes data set on GPUIf we have data set as vertical or horizontal strips, then let quantum simulation engine label the images as either bars or stripes. we want toy quantum circuit to prove of concept that we can then scale up to multi-node multi-GPU later.For more detail at [5].import matplotlib.pyplot as pltBAS = [[1, 1, 0, 0], [0, 0, 1, 1], [1, 0, 1, 0], [0, 1, 0, 1]]j = 1plt.figure(figsize=[3, 3])for i in BAS: plt.subplot(2, 2, j) j += 1 plt.imshow(np.reshape(i, [2, 2]), cmap=\"gray\") plt.xticks([]) plt.yticks([])def block(weights, wires): qml.RY(weights[0], wires=wires[0]) qml.RY(weights[1], wires=wires[1]) qml.CNOT(wires=wires)#dev = qml.device(\"default.qubit\", wires=4)dev = qml.device('lightning.gpu', wires=4)@qml.qnode(dev)def circuit(image, template_weights): qml.BasisStatePreparation(image, wires=range(4)) qml.TTN( wires=range(4), n_block_wires=2, block=block, n_params_block=2, template_weights=template_weights, ) return qml.expval(qml.PauliZ(wires=3))weights = np.random.random(size=[3, 2])fig, ax = qml.draw_mpl(circuit, expansion_strategy=\"device\")(BAS[0], weights)fig.set_size_inches((6, 3.5))def costfunc(params): cost = 0 for i in range(len(BAS)): if i &lt; len(BAS) / 2: cost += circuit(BAS[i], params) else: cost -= circuit(BAS[i], params) return costparams = np.random.random(size=[3, 2], requires_grad=True)optimizer = qml.GradientDescentOptimizer(stepsize=0.1)for k in range(100): if k % 20 == 0: print(f\"Step {k}, cost: {costfunc(params)}\") params = optimizer.step(costfunc, params)Step 0, cost: -0.4109040373994175Step 20, cost: -3.999999106074138Step 40, cost: -3.9999999999999996Step 60, cost: -4.000000000000001Step 80, cost: -3.999999999999999for image in BAS: fig, ax = qml.draw_mpl(circuit, expansion_strategy=\"device\")(image, params) plt.figure(figsize=[1.8, 1.8]) plt.imshow(np.reshape(image, [2, 2]), cmap=\"gray\") plt.title( f\"Exp. Val. = {circuit(image,params):.0f};\" + f\" Label = {'Bars' if circuit(image,params)&gt;0 else 'Stripes'}\", fontsize=8, ) plt.xticks([]) plt.yticks([])Reference:1.Quantum Tensor Networks and Entanglement https://cordis.europa.eu/project/id/6479052.Achieving Supercomputing-Scale Quantum Circuit Simulation with the NVIDIA DGX cuQuantum Appliancehttps://developer.nvidia.com/blog/achieving-supercomputing-scale-quantum-circuit-simulation-with-the-dgx-cuquantum-appliance/3.Lectures on Quantum Tensor Networks, Jacob Biamontehttps://arxiv.org/abs/1912.100494.Lightning-fast simulations with PennyLane and the NVIDIA cuQuantum SDKhttps://pennylane.ai/blog/2022/07/lightning-fast-simulations-with-pennylane-and-the-nvidia-cuquantum-sdk/5.Tensor-network quantum circuitshttps://pennylane.ai/qml/demos/tutorial_tn_circuits.html " }, { "title": "Quantum Drug Discovery", "url": "/posts/Quantum-Drug-Discovery/", "categories": "", "tags": "", "date": "2022-11-17 00:00:00 +0700", "snippet": "Drug Discovery: Protein Folding on IBM’s Qiskit Quantum Information Framework : NVIDIA A100 exascale.mahidol.ac.thBefore Covid-19 there is shown of obstacles for Quantum Supremacy[7]. December 2021, simulating the sycamore quantum supremacy circuit hooked our future “optimazation algorithms” imagination[8]. After than we have worked cuQuantum but there is not progress after a year. Until we get one motivation that we can try quantum information on GPU[9]. Finally, end up with IBM’s Qiskit framework for two reasons that very youtube video and tutorial[10]. The second that Qiskit drawn our attention is “Protien folding”[11]. Having been tried on QAOA on GPUs, we are VQE is promissing.The follo detail actually 99.9999% from the source [11] with migration to run on GPUs and cuQuantum.IntroductionThe structure and function of many natural and human-engineeredproteins is still only poorly understood. As a result, our understanding ofprocesses connected with protein folding, such as those encountered inAlzheimer’s disease, vaccine development, and crop improvementresearch, has remained limited.Unfolded polypeptides have a very large number of degrees of freedomand thus an enormous number of potential conformations. For example, achain with $100$ aminoacids has on the order of $10^{47}$ conformations. Inreality, however, many proteins fold to their native structure withinseconds. This is known as Levinthal’s paradox [1].The exponential growth of potential conformations with chain lengthmakes the problem intractable for classical computers. In the quantumframework, our resource-efficient algorithm scales linearly withthe number of aminoacids N.The goal of this work is to determine the minimum energy conformation of a protein. Starting from a random configuration, the protein’s structure is optimized to lower the energy. This can be achieved by encoding the protein folding problem into a qubit operator and ensuring that all physical constraints are satisfied.For the problem encoding we use: Configuration qubits: qubits that are used to describe the configurations and the relative position of the different beads Interaction qubits: qubits that encode interactions between the different aminoacids For our case we use a tetrahedral lattice (diamond shape lattice) where we encode the movement through the configuration qubits (see image below).The Hamiltonian of the system for a set of qubits $\\mathbf{q}={\\mathbf{q}{cf}, \\mathbf{q}{in}}$ is\\[H(\\mathbf{q}) = H_{gc}(\\mathbf{q}_{cf}) + H_{ch}(\\mathbf{q}_{cf}) + H_{in}(\\mathbf{q}_{cf}, \\mathbf{q}_{in})\\]where $H_{gc}$ is the geometrical constraint term (governing the growth of the primary sequence of aminoacids without bifurcations) $H_{ch}$ is the chirality constraint (enforcing the right stereochemistry for the system) $H_{in}$ is the interaction energy terms of the system. In our case we consider only nearest neighbor interactions. Further details about the used model and the encoding of the problem can be found in [2].! git clone https://github.com/qiskit-research/qiskit-research.git! cd qiskit-research &amp;&amp; pip install .from qiskit_research.protein_folding.interactions.random_interaction import ( RandomInteraction,)from qiskit_research.protein_folding.interactions.miyazawa_jernigan_interaction import ( MiyazawaJerniganInteraction,)from qiskit_research.protein_folding.peptide.peptide import Peptidefrom qiskit_research.protein_folding.protein_folding_problem import ( ProteinFoldingProblem,)from qiskit_research.protein_folding.penalty_parameters import PenaltyParametersfrom qiskit.utils import algorithm_globals, QuantumInstancealgorithm_globals.random_seed = 23Protein Main ChainThe Protein consists of a main chain that is a linear chain of aminoacids. For the naming of different residues we use the one-letter code as defined in Ref. [3]. Further details about the naming and the type of aminoacids can also be found in [4].For this particular case we demonstrate the generation of the qubit operator in a neuropeptide with the main chain consisting of 7 aminoacids with letter codes APRLRFY (see also [2]).main_chain = \"APRLRFY\"Side ChainsBeyond the main chain of the protein there may be aminoacids attached to the residues of the main chain. Our model allows for side chains of the maximum length of one. Elongated side chains would require the introduction of additional penalty terms which are still under development. In this example we do not consider any side chains to keep the real structure of the neuropeptide.side_chains = [\"\"] * 7Interaction between AminoacidsFor the description of inter-residue contacts for proteins we use knowledge-based (statistical) potentials derived using quasi-chemical approximation. The potentials used here are introduced by Miyazawa, S. and Jernigan, R. L. in [5].Beyond this model we also allow for random contact maps (interactions) that provide a random interaction map. One can also introduce a custom interaction map that enhances certain configurations of the protein (e.g. alpha helix, beta sheet etc).random_interaction = RandomInteraction()mj_interaction = MiyazawaJerniganInteraction()Physical ConstraintsTo ensure that all physical constraints are respected we introduce penalty functions. The different penalty terms used are: penalty_chiral: A penalty parameter used to impose the right chirality. penalty_back: A penalty parameter used to penalize turns along the same axis. This term is used to eliminate sequences where the same axis is chosen twice in a row. In this way we do not allow for a chain to fold back into itself. penalty_1: A penalty parameter used to penalize local overlap between beads within a nearest neighbor contact. penalty_back = 10penalty_chiral = 10penalty_1 = 10penalty_terms = PenaltyParameters(penalty_chiral, penalty_back, penalty_1)Peptide DefinitionBased on the main chain and possible side chains we define the peptide object that includes all the structural information of the modeled system.peptide = Peptide(main_chain, side_chains)Protein Folding ProblemBased on the defined peptide, the interaction (contact map) and the penalty terms we defined for our model we define the protein folding problem that returns qubit operators.protein_folding_problem = ProteinFoldingProblem(peptide, mj_interaction, penalty_terms)qubit_op = protein_folding_problem.qubit_op()print(qubit_op)1613.5895000000003 * IIIIIIIII+ 487.5 * IIIIIIZII- 192.5 * IIIIIIIZZ+ 192.5 * IIIIIIZZZ- 195.0 * IIIIZIZII- 195.0 * IIIIIZIZI- 195.0 * IIIIZZZZI- 95.0 * IIZIZIIII- 95.0 * IIIZIZIII- 95.0 * IIZZZZIII+ 295.0 * IIIIIIZZI- 497.5 * IIIIZIIII- 300.0 * IIIIZZIII+ 195.0 * IIIIIIIIZ+ 197.5 * IIIIIZIIZ- 197.5 * IIIIZZIIZ- 904.2875 * IZIIIIIII- 295.0 * IZIIIIZII- 197.5 * IZIIIIZZI+ 302.5 * IZIIZIIII+ 202.5 * IZIIZZIII+ 100.0 * IZIIZIZII+ 100.0 * IZIIIZIZI+ 100.0 * IZIIZZZZI- 200.0 * IZIIIIIIZ+ 97.5 * IZIIIIIZZ- 97.5 * IZIIIIZZZ- 100.0 * IZIIIZIIZ+ 100.0 * IZIIZZIIZ+ 100.0 * IIIIIIIZI- 100.0 * IIIIIZIII+ 2.5 * IZIIIIIZI- 2.5 * IZIIIZIII+ 192.5 * IIZIIIIII+ 95.0 * IIZZIIIII+ 97.5 * IIZIIIZII+ 97.5 * IIIZIIIZI+ 97.5 * IIZZIIZZI- 97.5 * IIIZIIIIZ+ 97.5 * IIZZIIIIZ+ 7.5 * IZZIIIIII+ 5.0 * IZZZIIIII+ 2.5 * IZZIIIZII+ 2.5 * IZIZIIIZI+ 2.5 * IZZZIIZZI- 2.5 * IZZIZIIII- 2.5 * IZIZIZIII- 2.5 * IZZZZZIII- 2.5 * IZIZIIIIZ+ 2.5 * IZZZIIIIZ+ 105.0 * IIIZIIIII- 701.802 * ZIIIIIIII- 195.0 * ZIIIIIZII- 102.5 * ZIIIIIIZI- 97.5 * ZIIIIIZZI+ 195.0 * ZIIIZIIII+ 102.5 * ZIIIIZIII+ 97.5 * ZIIIZZIII- 200.0 * ZIZIIIIII- 105.0 * ZIIZIIIII- 100.0 * ZIZZIIIII+ 97.5 * ZIIIZIZII- 100.0 * ZIZIIIZII+ 97.5 * ZIIIIZIZI- 100.0 * ZIIZIIIZI+ 97.5 * ZIIIZZZZI- 100.0 * ZIZZIIZZI+ 100.0 * ZIZIZIIII+ 100.0 * ZIIZIZIII+ 100.0 * ZIZZZZIII+ 97.5 * ZIIIIIIZZ- 97.5 * ZIIIIIZZZ- 97.5 * ZIIIIZIIZ+ 97.5 * ZIIIZZIIZ+ 100.0 * ZIIZIIIIZ- 100.0 * ZIZZIIIIZ+ 5.0 * ZIIIIIIIZUsing VQE with CVaR expectation value for the solution of the problemThe problem that we are tackling has now implemented all the physical constraints and has a diagonal Hamiltonian. For the particular case we are targeting the single bitstring that gives us the minimum energy (corresponding to the folded structure of the protein). Thus, we can use the Variational Quantum Eigensolver with Conditional Value at Risk (CVaR) expectation values for the solution of the problem and for finding the minimum configuration energy [6] . We follow the same approach as in Ref. [2] but here we use COBYLA for the classical optimization part. One can also use the standard VQE or QAOA algorithm for the solution of the problem, though as discussed in Ref. [2] CVaR is more suitable.from qiskit.circuit.library import RealAmplitudesfrom qiskit.algorithms.optimizers import COBYLAfrom qiskit.algorithms import NumPyMinimumEigensolver, VQEfrom qiskit.opflow import PauliExpectation, CVaRExpectation#from qiskit import execute, Aerfrom qiskit.providers.aer import *import time# set classical optimizeroptimizer = COBYLA(maxiter=50)# set variational ansatzansatz = RealAmplitudes(reps=1)# set the backend#backend_name = \"aer_simulator\" # CPU configure#backend_name = \"aer_simulator_statevector\" # GPU configure#backend_name = AerSimulator(method = 'statevector',device = 'GPU', blocking_qubits=20)#backend_name = AerSimulator(method = 'statevector',device = 'GPU')backend_name = AerSimulator(method = 'automatic',device = 'GPU',blocking_qubits=10)#backend_name = AerSimulator(method = 'automatic')#backend_name = 'qasm_simulator'backend = QuantumInstance(# Aer.get_backend(backend_name), backend_name, shots=8192, seed_transpiler=algorithm_globals.random_seed, seed_simulator=algorithm_globals.random_seed,)counts = []values = []def store_intermediate_result(eval_count, parameters, mean, std): counts.append(eval_count) values.append(mean)# initialize CVaR_alpha objective with alpha = 0.1cvar_exp = CVaRExpectation(0.1, PauliExpectation())# initialize VQE using CVaRvqe = VQE( expectation=cvar_exp, #expectation=None, optimizer=optimizer, ansatz=ansatz, quantum_instance=backend, callback=store_intermediate_result, #include_custom=True, # for statevector simulatio, set True, if expectation = None)start = time.process_time()raw_result = vqe.compute_minimum_eigenvalue(qubit_op)print(time.process_time() - start)print(raw_result)/home/snit.san/miniconda3/envs/Qiskit/lib/python3.10/site-packages/qiskit/algorithms/minimum_eigen_solvers/vqe.py:625: RuntimeWarning: invalid value encountered in sqrt estimator_error = np.sqrt(variance / self.quantum_instance.run_config.shots)22.066488650000004{ 'aux_operator_eigenvalues': None, 'cost_function_evals': 50, 'eigenstate': { '000000101': 0.015625, '000000110': 0.029231698334171417, '000000111': 0.011048543456039806, '000010000': 0.011048543456039806, '000010101': 0.011048543456039806, '000010110': 0.019136638615493577, '000110110': 0.011048543456039806, '000111000': 0.011048543456039806, '000111001': 0.011048543456039806, '001000000': 0.038273277230987154, '001000001': 0.06810779599282303, '001000010': 0.06346905003621844, '001000011': 0.015625, '001000101': 0.15934435979977452, '001000110': 0.2910615001593306, '001000111': 0.05182226234930312, '001001000': 0.036643873123620545, '001001001': 0.0924387466109315, '001001010': 0.07328774624724109, '001001100': 0.011048543456039806, '001001101': 0.03125, '001001110': 0.059498227389561786, '001010000': 0.019136638615493577, '001010001': 0.029231698334171417, '001010010': 0.02209708691207961, '001010011': 0.011048543456039806, '001010100': 0.011048543456039806, '001010101': 0.09568319307746789, '001010110': 0.16275520824999734, '001010111': 0.03983608994994363, '001011001': 0.02209708691207961, '001011010': 0.011048543456039806, '001011100': 0.011048543456039806, '001011101': 0.036643873123620545, '001011110': 0.05740991584648074, '001100001': 0.03125, '001100010': 0.019136638615493577, '001100101': 0.03314563036811941, '001100110': 0.07328774624724109, '001100111': 0.015625, '001101000': 0.06987712429686843, '001101001': 0.13975424859373686, '001101010': 0.10597390598633231, '001101011': 0.036643873123620545, '001101101': 0.034938562148434216, '001101110': 0.06899813176818631, '001110000': 0.05633673867912483, '001110001': 0.11587810136086973, '001110010': 0.0897587913521567, '001110011': 0.024705294220065465, '001110101': 0.11744762795603834, '001110110': 0.22371595411369302, '001110111': 0.0427908248050911, '001111000': 0.12153397801643785, '001111001': 0.2602864257649638, '001111010': 0.21079277442550065, '001111011': 0.03983608994994363, '001111101': 0.015625, '001111110': 0.027063293868263706, '010000001': 0.015625, '010000010': 0.015625, '010000101': 0.029231698334171417, '010000110': 0.046875, '010000111': 0.011048543456039806, '010001000': 0.011048543456039806, '010001001': 0.02209708691207961, '010001010': 0.019136638615493577, '010001110': 0.011048543456039806, '010001111': 0.011048543456039806, '010010001': 0.011048543456039806, '010010101': 0.02209708691207961, '010010110': 0.029231698334171417, '010010111': 0.011048543456039806, '010011110': 0.011048543456039806, '010100101': 0.015625, '010100110': 0.02209708691207961, '010101000': 0.011048543456039806, '010101001': 0.029231698334171417, '010101010': 0.02209708691207961, '010101101': 0.011048543456039806, '010101110': 0.019136638615493577, '010110000': 0.015625, '010110001': 0.02209708691207961, '010110010': 0.015625, '010110101': 0.02209708691207961, '010110110': 0.034938562148434216, '010111000': 0.027063293868263706, '010111001': 0.05633673867912483, '010111010': 0.05063078670631141, '010111011': 0.011048543456039806, '011000101': 0.011048543456039806, '011000110': 0.015625, '011001010': 0.011048543456039806, '011101010': 0.011048543456039806, '011110110': 0.011048543456039806, '011111001': 0.02209708691207961, '011111010': 0.02209708691207961, '100000001': 0.019136638615493577, '100000100': 0.011048543456039806, '100000101': 0.015625, '100000110': 0.029231698334171417, '100010010': 0.011048543456039806, '100010101': 0.011048543456039806, '100010110': 0.029231698334171417, '100110010': 0.011048543456039806, '100110110': 0.011048543456039806, '100111001': 0.015625, '100111010': 0.015625, '101000000': 0.04555431167847891, '101000001': 0.08193819126329309, '101000010': 0.061515686515717274, '101000011': 0.02209708691207961, '101000100': 0.015625, '101000101': 0.16350351200356522, '101000110': 0.31483502624390447, '101000111': 0.04941058844013093, '101001000': 0.034938562148434216, '101001001': 0.09043622580304864, '101001010': 0.08118988160479113, '101001011': 0.024705294220065465, '101001101': 0.02209708691207961, '101001110': 0.06051536478449089, '101001111': 0.019136638615493577, '101010000': 0.02209708691207961, '101010001': 0.015625, '101010010': 0.02209708691207961, '101010101': 0.0897587913521567, '101010110': 0.16275520824999734, '101010111': 0.024705294220065465, '101011010': 0.015625, '101011100': 0.011048543456039806, '101011101': 0.019136638615493577, '101011110': 0.05412658773652741, '101011111': 0.019136638615493577, '101100000': 0.011048543456039806, '101100001': 0.027063293868263706, '101100010': 0.015625, '101100101': 0.03314563036811941, '101100110': 0.06810779599282303, '101100111': 0.011048543456039806, '101101000': 0.06346905003621844, '101101001': 0.12597277731716483, '101101010': 0.10825317547305482, '101101011': 0.036643873123620545, '101101101': 0.05063078670631141, '101101110': 0.07574499777213015, '101101111': 0.015625, '101110000': 0.059498227389561786, '101110001': 0.12052537984798056, '101110010': 0.09631896879639025, '101110011': 0.02209708691207961, '101110101': 0.1269381000724369, '101110110': 0.23593232610221093, '101110111': 0.034938562148434216, '101111000': 0.12979099785809492, '101111001': 0.2679129406169101, '101111010': 0.22803936748947537, '101111011': 0.048159484398195125, '101111100': 0.011048543456039806, '101111101': 0.011048543456039806, '101111110': 0.034938562148434216, '110000010': 0.019136638615493577, '110000101': 0.03125, '110000110': 0.05846339666834283, '110000111': 0.011048543456039806, '110001001': 0.019136638615493577, '110001010': 0.011048543456039806, '110001110': 0.015625, '110010001': 0.011048543456039806, '110010101': 0.011048543456039806, '110010110': 0.038273277230987154, '110100010': 0.011048543456039806, '110100011': 0.011048543456039806, '110100100': 0.011048543456039806, '110101000': 0.02209708691207961, '110101001': 0.03125, '110101010': 0.011048543456039806, '110101110': 0.015625, '110110001': 0.011048543456039806, '110110010': 0.015625, '110110101': 0.03125, '110110110': 0.0427908248050911, '110110111': 0.011048543456039806, '110111000': 0.019136638615493577, '110111001': 0.05633673867912483, '110111010': 0.03983608994994363, '110111110': 0.011048543456039806, '111010110': 0.011048543456039806}, 'eigenvalue': (-1.3961062011717185+0j), 'optimal_circuit': None, 'optimal_parameters': { ParameterVectorElement(θ[3]): 0.9692262567242826, ParameterVectorElement(θ[4]): 1.2642867883228641, ParameterVectorElement(θ[14]): 0.8463792877027871, ParameterVectorElement(θ[16]): -0.014459268936528602, ParameterVectorElement(θ[12]): 2.18024157641206, ParameterVectorElement(θ[17]): -1.6753431921616952, ParameterVectorElement(θ[15]): 3.2569738080876025, ParameterVectorElement(θ[13]): 2.7683897737290772, ParameterVectorElement(θ[0]): 1.2838423033219764, ParameterVectorElement(θ[5]): 3.2075406912327287, ParameterVectorElement(θ[7]): -3.0610226240215836, ParameterVectorElement(θ[9]): -0.5499117056945564, ParameterVectorElement(θ[6]): 2.758502107235997, ParameterVectorElement(θ[11]): 1.6613895556624305, ParameterVectorElement(θ[10]): 0.783563408369476, ParameterVectorElement(θ[8]): 3.062947537861036, ParameterVectorElement(θ[1]): 2.5249570586597203, ParameterVectorElement(θ[2]): -2.0271296314251086}, 'optimal_point': array([ 1.2838423 , 2.52495706, -2.02712963, 0.96922626, 1.26428679, 3.20754069, 2.75850211, -3.06102262, 3.06294754, -0.54991171, 0.78356341, 1.66138956, 2.18024158, 2.76838977, 0.84637929, 3.25697381, -0.01445927, -1.67534319]), 'optimal_value': -1.3961062011717185, 'optimizer_evals': None, 'optimizer_result': None, 'optimizer_time': 22.18771505355835}import matplotlib.pyplot as pltfig = plt.figure()plt.plot(counts, values)plt.ylabel(\"Conformation Energy\")plt.xlabel(\"VQE Iterations\")fig.add_axes([0.44, 0.51, 0.44, 0.32])plt.plot(counts[40:], values[40:])plt.ylabel(\"Conformation Energy\")plt.xlabel(\"VQE Iterations\")plt.show()Visualizing the answerIn order to reduce computational costs, we have reduced the problem’s qubit operator to the minimum amount of qubits needed to represent the shape of the protein. In order to decode the answer we need to understand how this has been done. The shape of the protein has been encoded by a sequence of turns , ${0,1,2,3}$. Each turn represents a different direction in the lattice. For a main bead of $N_{aminoacids}$ in a lattice, we need $N_{aminoacids}-1$ turns in order to represent its shape. However, the orientation of the protein is not relevant to its energy. Therefore the first two turns of the shape can be set to $[1,0]$ without loss of generality. If the second bead does not have any side chain, we can also set the $6^{th}$ qubit to $[1]$ without breaking symmetry. Since the length of the secondary chains is always limited to $1$ we only need one turn to describe the shape of the chain.The total amount of qubits we need to represent the shape of the protein will be $2(N_{aminoacids}-3)$ if there is a secondary chain coming out of the second bead or $2(N_{aminoacids}-3) - 1$, otherwise. All the other qubits will remain unused during the optimization process. See:result = protein_folding_problem.interpret(raw_result=raw_result)print( \"The bitstring representing the shape of the protein during optimization is: \", result.turn_sequence,)print(\"The expanded expression is:\", result.get_result_binary_vector())The bitstring representing the shape of the protein during optimization is: 101000110The expanded expression is: 1______0_____________________________________________________________________________________________________________________________100011_0____Now that we know which qubits encode which information, we can decode the bitstring into the explicit turns that form the shape of the protein.print( f\"The folded protein's main sequence of turns is: {result.protein_shape_decoder.main_turns}\")print(f\"and the side turn sequences are: {result.protein_shape_decoder.side_turns}\")The folded protein's main sequence of turns is: [1, 0, 1, 3, 0, 1]and the side turn sequences are: [None, None, None, None, None, None, None]From this sequence of turns we can get the cartesian coordinates of each of the aminoacids of the protein.print(result.protein_shape_file_gen.get_xyz_data())[['A' '0.0' '0.0' '0.0'] ['P' '0.5773502691896258' '0.5773502691896258' '-0.5773502691896258'] ['R' '1.1547005383792517' '0.0' '-1.1547005383792517'] ['L' '1.7320508075688776' '0.5773502691896258' '-1.7320508075688776'] ['R' '1.154700538379252' '1.1547005383792517' '-2.3094010767585034'] ['F' '0.5773502691896261' '1.7320508075688776' '-1.7320508075688776'] ['Y' '2.220446049250313e-16' '1.154700538379252' '-1.154700538379252']]And finally, we can also plot the structure of the protein in 3D. Note that when rendered with the proper backend this plot can be interactively rotated.fig = result.get_figure(title=\"Protein Structure\", ticks=False, grid=True)fig.get_axes()[0].view_init(10, 70)And here is an example with side chains.peptide = Peptide(\"APRLR\", [\"\", \"\", \"F\", \"Y\", \"\"])protein_folding_problem = ProteinFoldingProblem(peptide, mj_interaction, penalty_terms)qubit_op = protein_folding_problem.qubit_op()raw_result = vqe.compute_minimum_eigenvalue(qubit_op)result_2 = protein_folding_problem.interpret(raw_result=raw_result)fig = result_2.get_figure(title=\"Protein Structure\", ticks=False, grid=True)fig.get_axes()[0].view_init(10, 60)References[1] https://en.wikipedia.org/wiki/Levinthal%27s_paradox [2] A.Robert, P.Barkoutsos, S.Woerner and I.Tavernelli, Resource-efficient quantum algorithm for protein folding, NPJ Quantum Information, 2021, https://doi.org/10.1038/s41534-021-00368-4 [3] IUPAC–IUB Commission on Biochemical Nomenclature (1972). \"A one-letter notation for aminoacid sequences\". Pure and Applied Chemistry. 31 (4): 641–645. doi:10.1351/pac197231040639. PMID 5080161.[4] https://en.wikipedia.org/wiki/Amino_acid [5] S. Miyazawa and R. L.Jernigan, Residue – Residue Potentials with a Favorable Contact Pair Term and an Unfavorable High Packing Density Term for Simulation and Threading, J. Mol. Biol.256, 623–644, 1996, Table 3, https://doi.org/10.1006/jmbi.1996.0114 [6] P.Barkoutsos, G. Nannichini, A.Robert, I.Tavernelli, S.Woerner, Improving Variational Quantum Optimization using CVaR, Quantum 4, 256, 2020, https://doi.org/10.22331/q-2020-04-20-256 [7] S.Suwanna, Key Obstacles for Quantum Supremacy, https://www.nectec.or.th/ace2019/wp-content/uploads/2019/09/20190909_SS09_Dr.Sujin_.pdf [8] F. Pan, simulating the sycamore quantum supremacy circuit, https://www.nectec.or.th/ace2019/wp-content/uploads/2019/09/20190909_SS09_Dr.Sujin_.pdf [9] L.J. O'Riordan, Lightning-fast simulations with PennyLane and the NVIDIA cuQuantum SDK, https://pennylane.ai/blog/2022/07/lightning-fast-simulations-with-pennylane-and-the-nvidia-cuquantum-sdk/ [10] IBM, Qiskit Textbook(beta), https://qiskit.org/learn/ [11] IBM, Qiskit Research , https://github.com/qiskit-research/qiskit-research import qiskit.tools.jupyter%qiskit_version_table%qiskit_copyrightVersion InformationQiskit SoftwareVersionqiskit-terra0.22.2qiskit-aer0.12.0qiskit-ibmq-provider0.19.2qiskit0.39.2qiskit-nature0.4.2qiskit-optimization0.4.0System informationPython version3.10.6Python compilerGCC 11.2.0Python buildmain, Oct 24 2022 16:07:47OSLinuxCPUs128Memory (Gb)2015.6843872070312Thu Nov 17 07:19:27 2022 +07This code is a part of Qiskit&copy; Copyright IBM 2017, 2022.This code is licensed under the Apache License, Version 2.0. You mayobtain a copy of this license in the LICENSE.txt file in the root directory of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.Any modifications or derivative works of this code must retain thiscopyright notice, and modified files need to carry a notice indicatingthat they have been altered from the originals.&lt;/div&gt;```python```" }, { "title": "Cpu_risc_v_layout_multi_university_wafer", "url": "/posts/CPU_RISC_V_Layout_multi_university_wafer/", "categories": "", "tags": "", "date": "2022-10-14 00:00:00 +0700", "snippet": "Chip RISC V CPU: Physical tape out in a Jupyter notebook on ExamScale ClusterMotivated by difficulty experiences in IC Design about 18 and 8 years ago, this note will save time and resource for next generation Electronics Engineering and Computer Science who are interested in digital and mixed-signal integrate circuit. If I could persuade you to rethink about Open Source tools for real-world digital/analog chip design and tape out for manufacture efabless University program efabless.com# $![image.png](attachment:460a7c8f-901b-46a3-bf6d-25d5c1d8e9eb.png)from IPython import displaydisplay.Image(\"https://efabless.com/lib_CUsguFEVafmoKCKW/klx999yu9pesnun9.png\")Figure: Multi-project-wafer at efabless.comIt might be four breakthroughs in open source IC design and tape out chip layout to fabricate at chip manufacture. OpenROAD Project:: Open source tools for complete and complex IC design processes. Compare to commercial tools, OpenLane based on OpenROAD can be applied to Automatic IC design flow which can reduce human interaction for less than 24 hours turn around time from Register Transfer Lever (RTL) to Layout tape process, GDS file.[1] Open Sky130 PDK, SkyWater Open Source PDK is a collaboration between Google and SkyWater Technology Foundry to provide a fully open source Process Design Kit and related resources, which can be used to create manufacturable designs at SkyWater’s facility. [2] Muti-project-wafer or MPW, began 1981 Metal Oxide Silicon Implementation Service), established by DARPA as a technical and human infrastructure for VLSI[3], many university course the course produced ‘multi-university, multi-project chip-design demonstration had been ended. New for opportunity for Open chip for university project has been started by Efabless with Skywater and Google partners. [4] High Performance Computing for CAD/CAM as we create chip layout rendering is a time-consuming task and sometimes lead to failure of project delivery. With GPU, it is not only speed we will achieve, but flexibility in programming is also countless. [5] This post will demonstration how to work out on IC design flow from RTL to GDS tape out as shown in following diagram.from IPython import displaydisplay.Image(\"https://antmicro.com/blog/images/openlane-flow.png\")Source[Antmicro · Improving the OpenLane ASIC build flow with open source SystemVerilog support]We will demonstrate how to generate physical IC layout design from Verilog RTL for RISC V CPU, named as Picorv32a[6]Step 0: Prepare Environment and Download EDABefore start jupyter notebook, on any head node, login node$conda create –name chipREal$conda activate chipReal$ mkdir chip_design_tape_out$ cd chip_design_tape_out$ git clone –depth=1 https://github.com/The-OpenROAD-Project/OpenLane%%writefile environment.ymlchannels: - litex-hub - conda-forgedependencies: - open_pdks.sky130A - magic - ngspice-lib - gdstk - python - pip - openroad - netgen - yosys - tcllib - pyyaml - click - pip: - cairosvg - pyspiceIn bash shell not jupyter notebookUpdate conda environment:$ conda env update –file environment.ymlStep 1: Prepare Makefile and env.py, from Docker to SingularityOn ExScale we cannot use Docker so we need to chagne defualt configuration to Singularity configuration in Makefile.%%writefile OpenLane/Makefile# Copyright 2020-2022 Efabless Corporation## Licensed under the Apache License, Version 2.0 (the \"License\");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.PYTHON_BIN ?= python3OPENLANE_DIR ?= $(shell pwd)DOCKER_OPTIONS = $(shell $(PYTHON_BIN) ./env.py docker-config)DOCKER_ARCH ?= $(shell $(PYTHON_BIN) ./docker/current_platform.py)# Allow Configuring Memory Limitsifneq (,$(DOCKER_SWAP)) # Set to -1 for unlimitedDOCKER_OPTIONS += --memory-swap=$(DOCKER_SWAP)endififneq (,$(DOCKER_MEMORY))DOCKER_OPTIONS += --memory=$(DOCKER_MEMORY)# To verify: cat /sys/fs/cgroup/memory/memory.limit_in_bytes inside the containerendif# Allow using GUIsUNAME_S = $(shell uname -s)ifeq ($(UNAME_S),Linux)DOCKER_OPTIONS += --env DISPLAY=$(DISPLAY) -B /tmp/.X11-unix:/tmp/.X11-unix -B $(HOME)/.Xauthority:/.Xauthority ifneq (\"$(wildcard $(HOME)/.openroad)\",\"\") DOCKER_OPTIONS += -B $(HOME)/.openroad:/.openroad endifendifTHREADS ?= 1ifneq (,$(ROUTING_CORES))DOCKER_OPTIONS += --env ROUTING_CORES=$(ROUTING_CORES)endifinclude ./dependencies/image_name.mkTEST_DESIGN ?= spmDESIGN_LIST ?= spmQUICK_RUN_DESIGN ?= spmBENCHMARK ?= regression_results/benchmark_results/SW_HD.csvREGRESSION_TAG ?= TEST_SW_HDFASTEST_TEST_SET_TAG ?= FASTEST_TEST_SETEXTENDED_TEST_SET_TAG ?= EXTENDED_TEST_SETPRINT_REM_DESIGNS_TIME ?= 0SKYWATER_COMMIT ?= $(shell $(PYTHON_BIN) ./dependencies/tool.py sky130 -f commit)OPEN_PDKS_COMMIT ?= $(shell $(PYTHON_BIN) ./dependencies/tool.py open_pdks -f commit)export PDK_ROOT ?= ./pdksexport PDK_ROOT := $(shell $(PYTHON_BIN) -c \"import os; print(os.path.realpath('$(PDK_ROOT)'), end='')\")PDK_OPTS = -B $(PDK_ROOT):$(PDK_ROOT) --env PDK_ROOT=$(PDK_ROOT)export PDK ?= sky130APDK_OPTS += --env PDK=$(PDK)ifneq ($(STD_CELL_LIBRARY),)export STD_CELL_LIBRARY ?= sky130_fd_sc_hdPDK_OPTS += --env STD_CELL_LIBRARY=$(STD_CELL_LIBRARY)endif# ./designs is mounted over ./install so env.tcl is not found inside the Docker# container if the user had previously installed it.ENV_START = singularity exec --nv\\\t-B $(OPENLANE_DIR):/openlane\\\t-B $(OPENLANE_DIR)/designs:/openlane/install\\\t$(PDK_OPTS)\\\t$(STD_CELL_OPTS)\\\t$(DOCKER_OPTIONS)#ENV_COMMAND = $(ENV_START) $(OPENLANE_IMAGE_NAME)-$(DOCKER_ARCH)ENV_COMMAND = $(ENV_START) openlane.sif ENV_RUN = singularity shell --nv\\ -B $(OPENLANE_DIR):/openlane\\ -B $(OPENLANE_DIR)/designs:/openlane/install\\ $(PDK_OPTS)\\ $(STD_CELL_OPTS)\\ $(DOCKER_OPTIONS)ENV_COMMAND_RUN = $(ENV_RUN) openlane.sif.DEFAULT_GOAL := all.PHONY: allall: get-openlane pdk.PHONY: openlaneopenlane: venv/created\t@PYTHON_BIN=$(PWD)/venv/bin/$(PYTHON_BIN) $(MAKE) -C docker openlane.PHONY: openlane-and-push-toolsopenlane-and-push-tools: venv/created\t@PYTHON_BIN=$(PWD)/venv/bin/$(PYTHON_BIN) BUILD_IF_CANT_PULL=1 BUILD_IF_CANT_PULL_THEN_PUSH=1 $(MAKE) -C docker openlanepull-openlane:\t@singularity pull openlane.sif \"docker://$(OPENLANE_IMAGE_NAME)\"get-openlane:\t@$(MAKE) pull-openlane || $(MAKE) openlane.PHONY: mountmount:\tcd $(OPENLANE_DIR) &amp;&amp; \\\t$(ENV_COMMAND_RUN) \t.PHONY: pdkpdk: venv/created\t./venv/bin/$(PYTHON_BIN) -m pip install --upgrade --no-cache-dir volare\t./venv/bin/volare enable.PHONY: surveysurvey:\t$(PYTHON_BIN) ./env.py issue-survey.PHONY: lintlint: venv/created\t./venv/bin/black --check .\t./venv/bin/flake8 ..PHONY: start-build-envstart-build-env: venv/created\tbash -c \"bash --rcfile &lt;(cat ~/.bashrc ./venv/bin/activate)\"venv: venv/createdvenv/created: ./requirements.txt ./requirements_dev.txt ./requirements_lint.txt ./dependencies/python/precompile_time.txt ./dependencies/python/run_time.txt \trm -rf ./venv\t$(PYTHON_BIN) -m venv ./venv\t./venv/bin/$(PYTHON_BIN) -m pip install --upgrade --no-cache-dir pip\t./venv/bin/$(PYTHON_BIN) -m pip install --upgrade --no-cache-dir -r ./requirements_dev.txt\ttouch $@DLTAG=custom_design_List.PHONY: test_design_list fastest_test_set extended_test_setfastest_test_set: DESIGN_LIST=$(shell cat ./.github/test_sets/fastest_test_set)fastest_test_set: DLTAG=$(FASTEST_TEST_SET_TAG)fastest_test_set: test_design_listextended_test_set: DESIGN_LIST=$(shell cat ./.github/test_sets/extended_test_set)extended_test_set: DLTAG=$(EXTENDED_TEST_SET_TAG)extended_test_set: test_design_listtest_design_list:\tcd $(OPENLANE_DIR) &amp;&amp; \\\t\t$(ENV_COMMAND) sh -c \"\\\t\t\tpython3 run_designs.py\\\t\t\t--tag $(DLTAG)\\\t\t\t--threads $(THREADS)\\\t\t\t--print_rem $(PRINT_REM_DESIGNS_TIME)\\\t\t\t--benchmark $(BENCHMARK)\\\t\t\t$(DESIGN_LIST)\\\t\t\"# -u is needed, as the python buffers the stdout, so no output is generatedrun_issue_regression:\tcd $(OPENLANE_DIR) &amp;&amp; \\\t\t$(ENV_COMMAND) sh -c \"\\\t\t\tpython3 -um tests run $(ISSUE_REGRESSION_DESIGN)\"issue_regression_all:\tcd $(OPENLANE_DIR) &amp;&amp; \\\t\t$(ENV_COMMAND) sh -c \"\\\t\t\tpython3 -um tests run_all\".PHONY: testtest:\tcd $(OPENLANE_DIR) &amp;&amp; \\\t\t$(ENV_COMMAND) sh -c \"./flow.tcl -design $(TEST_DESIGN) -tag openlane_test -overwrite\"\t@[ -f $(OPENLANE_DIR)/designs/$(TEST_DESIGN)/runs/openlane_test/results/signoff/$(TEST_DESIGN).gds ] &amp;&amp; \\\t\techo \"Basic test passed\" || \\\t\techo \"Basic test failed\".PHONY: quick_runquick_run:\tcd $(OPENLANE_DIR) &amp;&amp; \\\t\t$(ENV_COMMAND) sh -c \"./flow.tcl -design $(QUICK_RUN_DESIGN)\".PHONY: veryclean clean_runs clean_resultsveryclean:\t@git clean -fdXclean_runs:\t@rm -rf ./designs/*/runs &amp;&amp; rm -rf ./_build/it_tc_logs &amp;&amp; echo \"Runs cleaned successfully.\" || echo \"Failed to delete runs.\"\t@rm -rf ./tests/*/runs &amp;&amp; echo \"Test runs cleaned successfully.\" || echo \"Failed to delete test runs.\"clean_results:\t@{ find regression_results -mindepth 1 -maxdepth 1 -type d | grep -v benchmark | xargs rm -rf ; } &amp;&amp; echo \"Results cleaned successfully.\" || echo \"Failed to delete results.\"Correct Docker Environment to SingularityBy modified env.py in OpenLane%%writefile OpenLane/env.py#!/usr/bin/env python3# Copyright 2021 Efabless Corporation## Licensed under the Apache License, Version 2.0 (the \"License\");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# Note to maintainers/contributors:## Ensure you don't use f strings, non-comment type hints or any other features# that wouldn't work on Python 3.3## Inevitably, some people won't read the Readme and then complain that the issue# survey doesn't work on their older Python versions. As long as it's compatible# with Python 3.3, this script will tell them that their python version is# below the minimum supported.import ioimport osimport sysimport getpassimport textwrapimport subprocessfrom os.path import abspath, dirnameopenlane_dir = dirname(abspath(__file__))is_root = os.geteuid() == 0# Commandsdef tool_list(): from dependencies.tool import Tool tools = Tool.from_metadata_yaml(open(\"./dependencies/tool_metadata.yml\").read()) for tool in tools.values(): print(\"%s %s\" % (tool.name, tool.version_string))def local_install(): from dependencies.installer import Installer installer = Installer() installer.run()def docker_config(): from dependencies.env_info import ContainerInfo cinfo = ContainerInfo.get() if cinfo is None: raise Exception(\"No container engine found.\")''' if cinfo.engine == \"docker\": if cinfo.rootless: print(\"-u 0\", end=\"\") else: uid = ( subprocess.check_output([\"id\", \"-u\", getpass.getuser()]) .decode(\"utf8\") .strip() ) gid = ( subprocess.check_output([\"id\", \"-g\", getpass.getuser()]) .decode(\"utf8\") .strip() ) print(\"--user %s:%s\" % (uid, gid), end=\"\")'''def issue_survey(): sys.path.append(os.path.dirname(__file__)) from dependencies.env_info import OSInfo from dependencies.version import parse as vp alerts = open(os.devnull, \"w\") final_report = \"\" os_info = OSInfo.get() final_report += textwrap.dedent( \"\"\"\\ Kernel: %s v%s \"\"\" % (os_info.kernel, os_info.kernel_version) ) if os_info.distro is not None: final_report += textwrap.dedent( \"\"\"\\ Distribution: %s %s \"\"\" % (os_info.distro, (os_info.distro_version or \"\")) ) python_version = vp(os_info.python_version) minimum_python_version = vp(\"3.6\") python_message = \"OK\" python_ok = True if python_version &lt; minimum_python_version: python_message = \"BELOW MINIMUM: UPDATE PYTHON\" python_ok = False final_report += textwrap.dedent( \"\"\"\\ Python: v%s (%s) \"\"\" % (python_version, python_message) ) if os_info.container_info is not None: container_version = vp(os_info.container_info.version) container_message = \"UNSUPPORTED\" if \"docker\" in os_info.container_info.engine: container_message = \"OK\" minimum_docker_version = vp(\"19.03.12\") if container_version &lt; minimum_docker_version: container_message = \"BELOW MINIMUM: UPDATE DOCKER\" final_report += textwrap.dedent( \"\"\"\\ Container Engine: %s v%s (%s) \"\"\" % (os_info.container_info.engine, container_version, container_message) ) elif os.path.exists( \"/git_version\" ): # i.e. if running inside the OpenLane container print(\"Alert: Running in container.\", file=alerts) final_report = ( textwrap.dedent( \"\"\"\\ WARNING: issue-survey appears to be running inside the OpenLane container. This makes it difficult to rule out issues with your environment. Unless instructed specifically to do so, please run this command outside the OpenLane container. ---\\n \"\"\" ) + final_report ) else: alert = ( \"Critical Alert: No Docker or Docker-compatible container engine was found.\" ) final_report += \"%s\\n\" % alert print(alert, file=alerts) if python_ok: from dependencies.get_tag import get_tag final_report += textwrap.dedent( \"\"\"\\ OpenLane Git Version: %s \"\"\" % get_tag() ) pip_ok = True try: import pip # noqa F401 except ImportError: pip_ok = False alert = ( \"pip: \" + \"INSTALLED\" if pip_ok else \"NOT FOUND: Please install pip using your operating system's package manager.\" ) final_report += \"%s\\n\" % alert print(alert, file=alerts) if pip_ok: venv_ok = True try: import venv # noqa F401 except ImportError: venv_ok = False alert = ( \"python-venv: \" + \"INSTALLED\" if venv_ok else \"NOT FOUND: Please install python-venv using your operating system's package manager.\" ) final_report += \"%s\\n\" % alert print(alert, file=alerts) if python_ok: from dependencies.verify_versions import verify_versions with io.StringIO() as f: status = \"OK\" try: mismatches = verify_versions( no_tools=True, report_file=f, pdk=os.getenv(\"PDK\") or \"sky130A\" ) if mismatches: status = \"MISMATCH\" except Exception: status = \"FAILED\" f.write(\"Failed to verify sky130A.\") f.write(\"\\n\") final_report += \"---\\nPDK Version Verification Status: %s\\n%s\" % ( status, f.getvalue(), ) try: git_log = subprocess.check_output( [ \"git\", \"log\", r\"--format=%h %cI %s - %an - %gs (%D)\", \"-n\", \"3\", ] ).decode(\"utf8\") final_report += \"---\\nGit Log (Last 3 Commits)\\n\\n\" + git_log remotes = subprocess.check_output([\"git\", \"remote\", \"-v\", \"show\"]).decode( \"utf8\" ) final_report += \"---\\nGit Remotes\\n\\n\" + remotes except subprocess.CalledProcessError: pass print(final_report, end=\"\")# Entry Pointdef main(): args = sys.argv[1:] commands = { \"tool-list\": tool_list, \"local-install\": local_install, \"docker-config\": docker_config, \"issue-survey\": issue_survey, } if len(args) &lt; 1 or args[0] not in commands.keys(): print( \"Usage: %s (%s)\" % (sys.argv[0], \"|\".join(commands.keys())), file=sys.stderr ) sys.exit(os.EX_USAGE) commands[args[0]]()if __name__ == \"__main__\": main()Step 2. Download the Docker Image and Install sky130 PDKDownload the Docker image of OpenLane and install sky130 PDK:!cd OpenLane &amp;&amp; makeStep 3: Validating your OpenLane InstallationTest the installed PDK and OpenLane:!cd OpenLane &amp;&amp; make testSucessful test looks like this:Basic test passedStep 4: Run IC Physical Layout Flow# Enter a Singularity session:$ cd OpenLane &amp;&amp; make mount# inside container shellSingularity&gt; cd /openlaneSingularity&gt; ./flow.tcl -design picorv32aStep 5: View RISCV CPU tape out Layout# still insice container shellSingularity&gt; klayout open browse of klayout folder to context path of the result dependence on your system. /designs/picorv32a/runs/RUN_2022.10.13_04.40.06/results/final/gds/picorv32.gdsead215ffd805.png# inside contain if you want to end of synthesisSingularity&gt; exitimport gdstkimport cairosvgfrom IPython.display import Imagelibrary = gdstk.read_gds('/home/snit.san/chip_design_tape_out/OpenLane/designs/picorv32a/runs/RUN_2022.10.14_10.45.33/results/final/gds/picorv32.gds')top_cells = library.top_level()top_cells[0].write_svg('picorv32.svg')cairosvg.svg2png(url='picorv32.svg', write_to='picorv32.png', scale=0.08)Image('picorv32.png')Singularity image is shared at /shared/software/singularity/images/openlane.sif. With given container image you can modify “Makefile” to mount software for your physcial desing.If you want to start design and simulation then it is short introduction to Verilator [7-8]References: OpenROAD project https://github.com/The-OpenROAD-Project Open Source Process Design Kit Skywave 130nm process [https://github.com/google/skywater-pdk] MPW https://en.wikipedia.org/wiki/Multi-project_wafer_service MPW university projgram http://efabless.com High-performance computing (HPC) for manufacturing https://learn.microsoft.com/en-us/azure/architecture/industries/manufacturing/compute-manufacturing-overview Picorv32 https://github.com/YosysHQ/picorv32 Verilog Primer https://inst.eecs.berkeley.edu/~eecs151/fa21/files/verilog/Verilog_Primer_Slides.pdf Veriator RTL somulation https://verilator.org/guide/latest/install.html Drawing Stick Diagrams https://www.southampton.ac.uk/~bim/notes/cad/guides/sticks.html " }, { "title": "Analog Ic Layout", "url": "/posts/Analog-IC-Layout/", "categories": "", "tags": "", "date": "2022-10-10 00:00:00 +0700", "snippet": "Python: Analog Inverter Chip Layout with Magic and PySpice Simulation on Sky 130nm PDKThis notebook demo how to create inverter loayout and extract analog net-list to simulate with Sky 130 nm PDK.Assume you are login to any compute node in exascale.mahidol.ac.th AI/HPC cluster.Considering CHIP, ASIC shortage after Covide-19, Euro WAR and Taiwan-China security and political issue. They are looking for Plan B, alternative CHIP factory. It is not goal to change country business focus but motivation for new generation to want to explore HOW TO BUID REAL CHIP as Electronics HOBBY, ASIC tape out from OpenSource EDA tools.Install Conda and packages before load this Jupter Notebook$ conda create –name chipReal$ vi environment.ymlchannels: litex-hub conda-forgedependencies: open_pdks.sky130a magic ngspice-lib gdstk python pip pip: cairosvg pyspice Update conda environment:$ conda env update –file environment.ymlPDK_ROOT=/home/snit.san/miniconda3/envs/chipReal/share/pdkPDK_PATH=/home/snit.san/miniconda3/envs/chipReal/share/pdk/sky130AUpdate PDK environment as your context.Draw a MOSFET Layout with magic%%script bash -c \"PDK_ROOT=/home/snit.san/miniconda3/envs/chipReal/share/pdk/ PDKPATH=/home/snit.san/miniconda3/envs/chipReal/share/pdk/sky130A magic -dnull -noconsole -rcfile /home/snit.san/miniconda3/envs/chipReal/share/pdk/sky130A/libs.tech/magic/sky130A.magicrc\"cellname rename (UNNAMED) mosfetbox 0 0 950nm 650nmpaint ndiffusionbox 400nm -600nm 550nm 1200nmpaint polysiliconbox 0 0 400nm 650nmlabel sourceport make 3box 550nm 0 950nm 650nmlabel drainport make 1box 400nm -600nm 550nm 0label gateport make 2extractext2spice lvsext2spice cthresh 0ext2spicegds labels nogds write mosfet.gdsMagic 8.3 revision 329 - Compiled on Sat Oct 8 23:33:28 UTC 2022.Starting magic under Tcl interpreterUsing the terminal as the console.Using NULL graphics device.Processing system .magicrc fileSourcing design .magicrc for technology sky130A ...2 Magic internal units = 1 LambdaInput style sky130(vendor): scaleFactor=2, multiplier=2The following types are not handled by extraction and will be treated as non-electrical types: ubm Scaled tech values by 2 / 1 to match internal grid scalingLoading sky130A Device Generator Menu ...Using technology \"sky130A\", version 1.0.341-2-gde752ecRoot cell box: width x height ( llx, lly ), ( urx, ury ) area (units^2)microns: 0.950 x 0.650 ( 0.000, 0.000), ( 0.950, 0.650) 0.618 lambda: 95.00 x 65.00 ( 0.00, 0.00 ), ( 95.00, 65.00) 6175.00 internal: 190 x 130 ( 0, 0 ), ( 190, 130 ) 24700 Root cell box: width x height ( llx, lly ), ( urx, ury ) area (units^2)microns: 0.150 x 1.800 ( 0.400, -0.600), ( 0.550, 1.200) 0.270 lambda: 15.00 x 180.00 ( 40.00, -60.00), ( 55.00, 120.00) 2700.00 internal: 30 x 360 ( 80, -120 ), ( 110, 240 ) 10800 Root cell box: width x height ( llx, lly ), ( urx, ury ) area (units^2)microns: 0.400 x 0.650 ( 0.000, 0.000), ( 0.400, 0.650) 0.260 lambda: 40.00 x 65.00 ( 0.00, 0.00 ), ( 40.00, 65.00) 2600.00 internal: 80 x 130 ( 0, 0 ), ( 80, 130 ) 10400 Moving label \"source\" from space to ndiff in cell mosfet.Root cell box: width x height ( llx, lly ), ( urx, ury ) area (units^2)microns: 0.400 x 0.650 ( 0.550, 0.000), ( 0.950, 0.650) 0.260 lambda: 40.00 x 65.00 ( 55.00, 0.00 ), ( 95.00, 65.00) 2600.00 internal: 80 x 130 ( 110, 0 ), ( 190, 130 ) 10400 Moving label \"drain\" from space to ndiff in cell mosfet.Root cell box: width x height ( llx, lly ), ( urx, ury ) area (units^2)microns: 0.150 x 0.600 ( 0.400, -0.600), ( 0.550, 0.000) 0.090 lambda: 15.00 x 60.00 ( 40.00, -60.00), ( 55.00, 0.00 ) 900.00 internal: 30 x 120 ( 80, -120 ), ( 110, 0 ) 3600 Moving label \"gate\" from space to poly in cell mosfet.Extracting mosfet into mosfet.ext:exttospice finished. Generating output for cell mosfetimport gdstkimport cairosvgfrom IPython.display import Imagelibrary = gdstk.read_gds('mosfet.gds')top_cells = library.top_level()top_cells[0].write_svg('mosfet.svg')cairosvg.svg2png(url='mosfet.svg', write_to='mosfet.png', scale=30.0)Image('mosfet.png')Simulate the MOFSET with PySpicefrom PySpice.Spice.Netlist import Circuit, SubCircuit, SubCircuitFactoryfrom PySpice.Unit import *import matplotlib.pyplot as pltcircuit = Circuit('mosfet0')circuit.lib('/home/snit.san/miniconda3/envs/chipReal/share/pdk/sky130A/libs.tech/ngspice/sky130.lib.spice', 'tt')circuit.include('mosfet.spice')circuit.X('mosfet0', 'mosfet', 'DRAIN', 'GATE', 'VGND')circuit.V('gnd', 'VGND', 0, 0)circuit.V('dd', 'VPWR', 'VGND', 1.8)circuit.R('', 'VPWR', 'DRAIN', '10k')circuit.PulseVoltageSource('Vin', 'GATE', 'VGND', initial_value=0@u_V, pulsed_value=1.8@u_V, rise_time=10@u_ps, fall_time=10@u_ps, pulse_width=1@u_ns, period=2@u_ns, delay_time=1@u_ns)print(str(circuit))simulator = circuit.simulator()analysis = simulator.transient(step_time=10@u_ps, end_time=2@u_ns)print('done')fig, ax = plt.subplots(figsize=(20, 10))ax.set_title('mosfet')ax.set_xlabel('time in 1e-14s')ax.set_ylabel('voltage in V')ax.plot(analysis.GATE)ax.plot(analysis.DRAIN)ax.legend(('GATE', 'DRAIN'))plt.tight_layout()plt.show().title mosfet0.include /home/snit.san/chip_design_tape_out/analog_sim/mosfet.spice.lib /home/snit.san/miniconda3/envs/chipReal/share/pdk/sky130A/libs.tech/ngspice/sky130.lib.spice ttXmosfet0 DRAIN GATE VGND mosfetVgnd VGND 0 0Vdd VPWR VGND 1.8R VPWR DRAIN 10kVVin GATE VGND DC 0V PULSE(0V 1.8V 1ns 10ps 10ps 1ns 2ns)doneReferences/Sources: Digital inverter with OpenLanehttps://developers.google.com/silicon/guides/digital-inverter-openlane" }, { "title": "Monai_mednist_tutorial", "url": "/posts/Monai_mednist_tutorial/", "categories": "", "tags": "", "date": "2022-09-23 00:00:00 +0700", "snippet": "Setup environment Verify Monai running on exascale.mahidol.ac.thWith terminal at any Compute Node, run Docker image with Singularity$ singularity run –nv docker://projectmonai/monaiRun notebook$ singularity shell –nv docker://projectmonai/monaiSingularity&gt; jupyter labMedical Image Classification Tutorial with the MedNIST DatasetIn this tutorial, we introduce an end-to-end training and evaluation example based on the MedNIST dataset.We’ll go through the following steps: Create a dataset for training and testing Use MONAI transforms to pre-process data Use the DenseNet from MONAI for classification Train the model with a PyTorch program Evaluate on test datasetimport torch!python -c \"import monai\" || pip install -q \"monai-weekly[pillow, tqdm]\"!python -c \"import matplotlib\" || pip install -q matplotlib%matplotlib inline!nvidia-smiFri Sep 23 17:26:58 2022 +-----------------------------------------------------------------------------+| NVIDIA-SMI 470.103.01 Driver Version: 470.103.01 CUDA Version: 11.7 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 NVIDIA A100-SXM... On | 00000000:07:00.0 Off | 0 || N/A 34C P0 68W / 400W | 3802MiB / 81251MiB | 5% Default || | | Disabled |+-------------------------------+----------------------+----------------------+| 1 NVIDIA A100-SXM... On | 00000000:0F:00.0 Off | 0 || N/A 28C P0 59W / 400W | 3MiB / 81251MiB | 0% Default || | | Disabled |+-------------------------------+----------------------+----------------------+| 2 NVIDIA A100-SXM... On | 00000000:47:00.0 Off | 0 || N/A 29C P0 58W / 400W | 3MiB / 81251MiB | 0% Default || | | Disabled |+-------------------------------+----------------------+----------------------+| 3 NVIDIA A100-SXM... On | 00000000:4E:00.0 Off | 0 || N/A 30C P0 58W / 400W | 3MiB / 81251MiB | 0% Default || | | Disabled |+-------------------------------+----------------------+----------------------+| 4 NVIDIA A100-SXM... On | 00000000:87:00.0 Off | 0 || N/A 37C P0 58W / 400W | 3MiB / 81251MiB | 0% Default || | | Disabled |+-------------------------------+----------------------+----------------------+| 5 NVIDIA A100-SXM... On | 00000000:90:00.0 Off | 0 || N/A 33C P0 64W / 400W | 3MiB / 81251MiB | 0% Default || | | Disabled |+-------------------------------+----------------------+----------------------+| 6 NVIDIA A100-SXM... On | 00000000:B7:00.0 Off | 0 || N/A 33C P0 61W / 400W | 3MiB / 81251MiB | 0% Default || | | Disabled |+-------------------------------+----------------------+----------------------+| 7 NVIDIA A100-SXM... On | 00000000:BD:00.0 Off | 0 || N/A 33C P0 59W / 400W | 3MiB / 81251MiB | 0% Default || | | Disabled |+-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||=============================================================================|| 0 N/A N/A 2429330 C /opt/conda/bin/python3.8 3799MiB |+-----------------------------------------------------------------------------+Setup imports# Copyright 2020 MONAI Consortium# Licensed under the Apache License, Version 2.0 (the \"License\");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.import osimport shutilimport tempfileimport matplotlib.pyplot as pltimport PILimport torchimport numpy as npfrom sklearn.metrics import classification_reportfrom monai.apps import download_and_extractfrom monai.config import print_configfrom monai.data import decollate_batch, DataLoaderfrom monai.metrics import ROCAUCMetricfrom monai.networks.nets import DenseNet121from monai.transforms import ( Activations, EnsureChannelFirst, AsDiscrete, Compose, LoadImage, RandFlip, RandRotate, RandZoom, ScaleIntensity,)from monai.utils import set_determinismprint_config()MONAI version: 1.0.0+5.g84e271ecNumpy version: 1.22.4Pytorch version: 1.13.0a0+d321be6MONAI flags: HAS_EXT = True, USE_COMPILED = False, USE_META_DICT = FalseMONAI rev id: 84e271ec939330e7cedf22b3871c4a2a62d3c2a2MONAI __file__: /opt/monai/monai/__init__.pyOptional dependencies:Pytorch Ignite version: 0.4.10Nibabel version: 4.0.2scikit-image version: 0.19.3Pillow version: 9.0.1Tensorboard version: 2.9.1gdown version: 4.5.1TorchVision version: 0.14.0a0tqdm version: 4.62.3lmdb version: 1.3.0psutil version: 5.9.0pandas version: 1.3.5einops version: 0.4.1transformers version: 4.21.3mlflow version: 1.29.0pynrrd version: 0.4.3For details about installing the optional dependencies, please visit: https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependenciesSetup data directoryYou can specify a directory with the MONAI_DATA_DIRECTORY environment variable.This allows you to save results and reuse downloads.If not specified a temporary directory will be used.directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")root_dir = tempfile.mkdtemp() if directory is None else directoryprint(root_dir)/tmp/tmpbasuc2txDownload datasetThe MedNIST dataset was gathered from several sets from TCIA,the RSNA Bone Age Challenge,and the NIH Chest X-ray dataset.The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic)under the Creative Commons CC BY-SA 4.0 license.If you use the MedNIST dataset, please acknowledge the source.resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\"md5 = \"0bc7306e7427e00ad1c5526a6677552d\"compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")data_dir = os.path.join(root_dir, \"MedNIST\")if not os.path.exists(data_dir): download_and_extract(resource, compressed_file, root_dir, md5)MedNIST.tar.gz: 59.0MB [00:07, 8.56MB/s] 2022-09-23 17:24:15,104 - INFO - Downloaded: /tmp/tmpbasuc2tx/MedNIST.tar.gz2022-09-23 17:24:15,204 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.2022-09-23 17:24:15,205 - INFO - Writing into directory: /tmp/tmpbasuc2tx.Set deterministic training for reproducibilityset_determinism(seed=0)Read image filenames from the dataset foldersFirst of all, check the dataset files and show some statistics.There are 6 folders in the dataset: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT,which should be used as the labels to train our classification model.class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))num_class = len(class_names)image_files = [ [ os.path.join(data_dir, class_names[i], x) for x in os.listdir(os.path.join(data_dir, class_names[i])) ] for i in range(num_class)]num_each = [len(image_files[i]) for i in range(num_class)]image_files_list = []image_class = []for i in range(num_class): image_files_list.extend(image_files[i]) image_class.extend([i] * num_each[i])num_total = len(image_class)image_width, image_height = PIL.Image.open(image_files_list[0]).sizeprint(f\"Total image count: {num_total}\")print(f\"Image dimensions: {image_width} x {image_height}\")print(f\"Label names: {class_names}\")print(f\"Label counts: {num_each}\")Total image count: 58954Image dimensions: 64 x 64Label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']Label counts: [10000, 8954, 10000, 10000, 10000, 10000]Randomly pick images from the dataset to visualize and checkplt.subplots(3, 3, figsize=(8, 8))for i, k in enumerate(np.random.randint(num_total, size=9)): im = PIL.Image.open(image_files_list[k]) arr = np.array(im) plt.subplot(3, 3, i + 1) plt.xlabel(class_names[image_class[k]]) plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)plt.tight_layout()plt.show()Prepare training, validation and test data listsRandomly select 10% of the dataset as validation and 10% as test.val_frac = 0.1test_frac = 0.1length = len(image_files_list)indices = np.arange(length)np.random.shuffle(indices)test_split = int(test_frac * length)val_split = int(val_frac * length) + test_splittest_indices = indices[:test_split]val_indices = indices[test_split:val_split]train_indices = indices[val_split:]train_x = [image_files_list[i] for i in train_indices]train_y = [image_class[i] for i in train_indices]val_x = [image_files_list[i] for i in val_indices]val_y = [image_class[i] for i in val_indices]test_x = [image_files_list[i] for i in test_indices]test_y = [image_class[i] for i in test_indices]print( f\"Training count: {len(train_x)}, Validation count: \" f\"{len(val_x)}, Test count: {len(test_x)}\")Training count: 47164, Validation count: 5895, Test count: 5895Define MONAI transforms, Dataset and Dataloader to pre-process datatrain_transforms = Compose( [ LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity(), RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True), RandFlip(spatial_axis=0, prob=0.5), RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5), ])val_transforms = Compose( [LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])y_pred_trans = Compose([Activations(softmax=True)])y_trans = Compose([AsDiscrete(to_onehot=num_class)])class MedNISTDataset(torch.utils.data.Dataset): def __init__(self, image_files, labels, transforms): self.image_files = image_files self.labels = labels self.transforms = transforms def __len__(self): return len(self.image_files) def __getitem__(self, index): return self.transforms(self.image_files[index]), self.labels[index]train_ds = MedNISTDataset(train_x, train_y, train_transforms)train_loader = DataLoader( train_ds, batch_size=300, shuffle=True, num_workers=10)val_ds = MedNISTDataset(val_x, val_y, val_transforms)val_loader = DataLoader( val_ds, batch_size=300, num_workers=10)test_ds = MedNISTDataset(test_x, test_y, val_transforms)test_loader = DataLoader( test_ds, batch_size=300, num_workers=10)Define network and optimizer Set learning rate for how much the model is updated per batch. Set total epoch number, as we have shuffle and random transforms, so the training data of every epoch is different.And as this is just a get start tutorial, let’s just train 4 epochs.If train 10 epochs, the model can achieve 100% accuracy on test dataset. Use DenseNet from MONAI and move to GPU devide, this DenseNet can support both 2D and 3D classification tasks. Use Adam optimizer.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)loss_function = torch.nn.CrossEntropyLoss()optimizer = torch.optim.Adam(model.parameters(), 1e-5)max_epochs = 4val_interval = 1auc_metric = ROCAUCMetric()print(device)cudaModel trainingExecute a typical PyTorch training that run epoch loop and step loop, and do validation after every epoch.Will save the model weights to file if got best validation accuracy.best_metric = -1best_metric_epoch = -1epoch_loss_values = []metric_values = []for epoch in range(max_epochs): print(\"-\" * 10) print(f\"epoch {epoch + 1}/{max_epochs}\") model.train() epoch_loss = 0 step = 0 for batch_data in train_loader: step += 1 inputs, labels = batch_data[0].to(device), batch_data[1].to(device) optimizer.zero_grad() outputs = model(inputs) loss = loss_function(outputs, labels) loss.backward() optimizer.step() epoch_loss += loss.item() print( f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\") epoch_len = len(train_ds) // train_loader.batch_size epoch_loss /= step epoch_loss_values.append(epoch_loss) print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\") if (epoch + 1) % val_interval == 0: model.eval() with torch.no_grad(): y_pred = torch.tensor([], dtype=torch.float32, device=device) y = torch.tensor([], dtype=torch.long, device=device) for val_data in val_loader: val_images, val_labels = ( val_data[0].to(device), val_data[1].to(device), ) y_pred = torch.cat([y_pred, model(val_images)], dim=0) y = torch.cat([y, val_labels], dim=0) y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)] y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)] auc_metric(y_pred_act, y_onehot) result = auc_metric.aggregate() auc_metric.reset() del y_pred_act, y_onehot metric_values.append(result) acc_value = torch.eq(y_pred.argmax(dim=1), y) acc_metric = acc_value.sum().item() / len(acc_value) if result &gt; best_metric: best_metric = result best_metric_epoch = epoch + 1 torch.save(model.state_dict(), os.path.join( root_dir, \"best_metric_model.pth\")) print(\"saved new best metric model\") print( f\"current epoch: {epoch + 1} current AUC: {result:.4f}\" f\" current accuracy: {acc_metric:.4f}\" f\" best AUC: {best_metric:.4f}\" f\" at epoch: {best_metric_epoch}\" )print( f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")----------epoch 1/41/157, train_loss: 1.79052/157, train_loss: 1.76263/157, train_loss: 1.73714/157, train_loss: 1.71165/157, train_loss: 1.68506/157, train_loss: 1.64777/157, train_loss: 1.64698/157, train_loss: 1.59679/157, train_loss: 1.577210/157, train_loss: 1.554111/157, train_loss: 1.525912/157, train_loss: 1.501813/157, train_loss: 1.479714/157, train_loss: 1.474615/157, train_loss: 1.462716/157, train_loss: 1.424217/157, train_loss: 1.410418/157, train_loss: 1.355619/157, train_loss: 1.345920/157, train_loss: 1.349721/157, train_loss: 1.316722/157, train_loss: 1.307023/157, train_loss: 1.289224/157, train_loss: 1.266525/157, train_loss: 1.288726/157, train_loss: 1.241927/157, train_loss: 1.215828/157, train_loss: 1.211729/157, train_loss: 1.159930/157, train_loss: 1.164831/157, train_loss: 1.137632/157, train_loss: 1.132533/157, train_loss: 1.105734/157, train_loss: 1.088235/157, train_loss: 1.087836/157, train_loss: 1.069037/157, train_loss: 1.040438/157, train_loss: 1.037339/157, train_loss: 1.028840/157, train_loss: 1.019841/157, train_loss: 1.053442/157, train_loss: 0.998943/157, train_loss: 0.958144/157, train_loss: 0.980045/157, train_loss: 0.943846/157, train_loss: 0.936447/157, train_loss: 0.932548/157, train_loss: 0.858349/157, train_loss: 0.932550/157, train_loss: 0.868551/157, train_loss: 0.860752/157, train_loss: 0.882453/157, train_loss: 0.885054/157, train_loss: 0.823655/157, train_loss: 0.807656/157, train_loss: 0.824357/157, train_loss: 0.800558/157, train_loss: 0.818459/157, train_loss: 0.801260/157, train_loss: 0.756761/157, train_loss: 0.763262/157, train_loss: 0.739663/157, train_loss: 0.759364/157, train_loss: 0.722865/157, train_loss: 0.720366/157, train_loss: 0.741167/157, train_loss: 0.700268/157, train_loss: 0.700969/157, train_loss: 0.731870/157, train_loss: 0.649271/157, train_loss: 0.683172/157, train_loss: 0.654073/157, train_loss: 0.661174/157, train_loss: 0.637175/157, train_loss: 0.651576/157, train_loss: 0.643677/157, train_loss: 0.612478/157, train_loss: 0.593979/157, train_loss: 0.643680/157, train_loss: 0.609681/157, train_loss: 0.577282/157, train_loss: 0.623883/157, train_loss: 0.583684/157, train_loss: 0.547685/157, train_loss: 0.527086/157, train_loss: 0.549387/157, train_loss: 0.513988/157, train_loss: 0.531689/157, train_loss: 0.488390/157, train_loss: 0.508291/157, train_loss: 0.507892/157, train_loss: 0.501993/157, train_loss: 0.484294/157, train_loss: 0.492495/157, train_loss: 0.465296/157, train_loss: 0.453197/157, train_loss: 0.436398/157, train_loss: 0.483099/157, train_loss: 0.4879100/157, train_loss: 0.4651101/157, train_loss: 0.4365102/157, train_loss: 0.4504103/157, train_loss: 0.4245104/157, train_loss: 0.4201105/157, train_loss: 0.4420106/157, train_loss: 0.4181107/157, train_loss: 0.4398108/157, train_loss: 0.4444109/157, train_loss: 0.4060110/157, train_loss: 0.4293111/157, train_loss: 0.3760112/157, train_loss: 0.3841113/157, train_loss: 0.3836114/157, train_loss: 0.3843115/157, train_loss: 0.3926116/157, train_loss: 0.3797117/157, train_loss: 0.3463118/157, train_loss: 0.3594119/157, train_loss: 0.3682120/157, train_loss: 0.3729121/157, train_loss: 0.3252122/157, train_loss: 0.3360123/157, train_loss: 0.3300124/157, train_loss: 0.3278125/157, train_loss: 0.3313126/157, train_loss: 0.3747127/157, train_loss: 0.3247128/157, train_loss: 0.3116129/157, train_loss: 0.3438130/157, train_loss: 0.2886131/157, train_loss: 0.3485132/157, train_loss: 0.3560133/157, train_loss: 0.3011134/157, train_loss: 0.3300135/157, train_loss: 0.3039136/157, train_loss: 0.2945137/157, train_loss: 0.3143138/157, train_loss: 0.2705139/157, train_loss: 0.3192140/157, train_loss: 0.3055141/157, train_loss: 0.2892142/157, train_loss: 0.2747143/157, train_loss: 0.2495144/157, train_loss: 0.2922145/157, train_loss: 0.2819146/157, train_loss: 0.2984147/157, train_loss: 0.2438148/157, train_loss: 0.2666149/157, train_loss: 0.2859150/157, train_loss: 0.2713151/157, train_loss: 0.2337152/157, train_loss: 0.2684153/157, train_loss: 0.2396154/157, train_loss: 0.2412155/157, train_loss: 0.2665156/157, train_loss: 0.2361157/157, train_loss: 0.2319158/157, train_loss: 0.2651epoch 1 average loss: 0.7282saved new best metric modelcurrent epoch: 1 current AUC: 0.9979 current accuracy: 0.9628 best AUC: 0.9979 at epoch: 1----------epoch 2/41/157, train_loss: 0.24302/157, train_loss: 0.24233/157, train_loss: 0.24494/157, train_loss: 0.22485/157, train_loss: 0.22926/157, train_loss: 0.21807/157, train_loss: 0.25148/157, train_loss: 0.24329/157, train_loss: 0.236110/157, train_loss: 0.194611/157, train_loss: 0.193512/157, train_loss: 0.246813/157, train_loss: 0.261814/157, train_loss: 0.205215/157, train_loss: 0.202616/157, train_loss: 0.204417/157, train_loss: 0.214418/157, train_loss: 0.230319/157, train_loss: 0.208420/157, train_loss: 0.201921/157, train_loss: 0.188422/157, train_loss: 0.210823/157, train_loss: 0.211024/157, train_loss: 0.198525/157, train_loss: 0.219226/157, train_loss: 0.184127/157, train_loss: 0.221228/157, train_loss: 0.186329/157, train_loss: 0.188730/157, train_loss: 0.196031/157, train_loss: 0.171332/157, train_loss: 0.168833/157, train_loss: 0.167434/157, train_loss: 0.188035/157, train_loss: 0.166636/157, train_loss: 0.184237/157, train_loss: 0.171338/157, train_loss: 0.197439/157, train_loss: 0.181040/157, train_loss: 0.194741/157, train_loss: 0.174942/157, train_loss: 0.232643/157, train_loss: 0.210644/157, train_loss: 0.162445/157, train_loss: 0.148746/157, train_loss: 0.172447/157, train_loss: 0.166948/157, train_loss: 0.173649/157, train_loss: 0.177550/157, train_loss: 0.172351/157, train_loss: 0.173552/157, train_loss: 0.155953/157, train_loss: 0.152654/157, train_loss: 0.160155/157, train_loss: 0.157056/157, train_loss: 0.161957/157, train_loss: 0.154158/157, train_loss: 0.183059/157, train_loss: 0.152660/157, train_loss: 0.189561/157, train_loss: 0.159362/157, train_loss: 0.159563/157, train_loss: 0.146664/157, train_loss: 0.126965/157, train_loss: 0.121566/157, train_loss: 0.143467/157, train_loss: 0.146968/157, train_loss: 0.144969/157, train_loss: 0.123470/157, train_loss: 0.167471/157, train_loss: 0.149872/157, train_loss: 0.149373/157, train_loss: 0.114774/157, train_loss: 0.136275/157, train_loss: 0.131176/157, train_loss: 0.112677/157, train_loss: 0.123178/157, train_loss: 0.136279/157, train_loss: 0.121480/157, train_loss: 0.132281/157, train_loss: 0.109482/157, train_loss: 0.132483/157, train_loss: 0.132984/157, train_loss: 0.106485/157, train_loss: 0.140286/157, train_loss: 0.135487/157, train_loss: 0.125088/157, train_loss: 0.131089/157, train_loss: 0.108790/157, train_loss: 0.116791/157, train_loss: 0.120492/157, train_loss: 0.124493/157, train_loss: 0.125094/157, train_loss: 0.142495/157, train_loss: 0.132896/157, train_loss: 0.108897/157, train_loss: 0.131798/157, train_loss: 0.098799/157, train_loss: 0.1127100/157, train_loss: 0.0909101/157, train_loss: 0.1434102/157, train_loss: 0.1138103/157, train_loss: 0.1210104/157, train_loss: 0.0901105/157, train_loss: 0.0986106/157, train_loss: 0.1226107/157, train_loss: 0.1076108/157, train_loss: 0.1164109/157, train_loss: 0.1077110/157, train_loss: 0.1028111/157, train_loss: 0.0874112/157, train_loss: 0.0962113/157, train_loss: 0.1147114/157, train_loss: 0.0992115/157, train_loss: 0.0848116/157, train_loss: 0.1218117/157, train_loss: 0.0939118/157, train_loss: 0.1227119/157, train_loss: 0.1069120/157, train_loss: 0.1095121/157, train_loss: 0.1252122/157, train_loss: 0.0996123/157, train_loss: 0.0844124/157, train_loss: 0.0979125/157, train_loss: 0.1441126/157, train_loss: 0.1036127/157, train_loss: 0.1001128/157, train_loss: 0.0950129/157, train_loss: 0.1022130/157, train_loss: 0.0776131/157, train_loss: 0.0850132/157, train_loss: 0.1019133/157, train_loss: 0.1034134/157, train_loss: 0.0910135/157, train_loss: 0.0986136/157, train_loss: 0.0765137/157, train_loss: 0.0908138/157, train_loss: 0.1176139/157, train_loss: 0.1113140/157, train_loss: 0.0779141/157, train_loss: 0.0871142/157, train_loss: 0.0958143/157, train_loss: 0.0876144/157, train_loss: 0.1181145/157, train_loss: 0.1112146/157, train_loss: 0.0980147/157, train_loss: 0.0933148/157, train_loss: 0.1106149/157, train_loss: 0.0818150/157, train_loss: 0.0976151/157, train_loss: 0.1008152/157, train_loss: 0.0950153/157, train_loss: 0.0954154/157, train_loss: 0.0822155/157, train_loss: 0.0936156/157, train_loss: 0.0946157/157, train_loss: 0.0893158/157, train_loss: 0.2379epoch 2 average loss: 0.1450saved new best metric modelcurrent epoch: 2 current AUC: 0.9998 current accuracy: 0.9869 best AUC: 0.9998 at epoch: 2----------epoch 3/41/157, train_loss: 0.09692/157, train_loss: 0.08513/157, train_loss: 0.07654/157, train_loss: 0.07365/157, train_loss: 0.09096/157, train_loss: 0.07887/157, train_loss: 0.08878/157, train_loss: 0.07499/157, train_loss: 0.084210/157, train_loss: 0.083711/157, train_loss: 0.076812/157, train_loss: 0.073113/157, train_loss: 0.082714/157, train_loss: 0.069215/157, train_loss: 0.069116/157, train_loss: 0.090317/157, train_loss: 0.077418/157, train_loss: 0.084319/157, train_loss: 0.071520/157, train_loss: 0.075821/157, train_loss: 0.086822/157, train_loss: 0.069623/157, train_loss: 0.077524/157, train_loss: 0.107325/157, train_loss: 0.121026/157, train_loss: 0.066827/157, train_loss: 0.059928/157, train_loss: 0.063329/157, train_loss: 0.076030/157, train_loss: 0.089931/157, train_loss: 0.084532/157, train_loss: 0.088933/157, train_loss: 0.073734/157, train_loss: 0.070335/157, train_loss: 0.075836/157, train_loss: 0.071137/157, train_loss: 0.078138/157, train_loss: 0.063339/157, train_loss: 0.077440/157, train_loss: 0.061541/157, train_loss: 0.065742/157, train_loss: 0.089143/157, train_loss: 0.092744/157, train_loss: 0.067445/157, train_loss: 0.073446/157, train_loss: 0.086447/157, train_loss: 0.056748/157, train_loss: 0.092249/157, train_loss: 0.061350/157, train_loss: 0.069651/157, train_loss: 0.095952/157, train_loss: 0.085253/157, train_loss: 0.084354/157, train_loss: 0.064355/157, train_loss: 0.066656/157, train_loss: 0.094857/157, train_loss: 0.062058/157, train_loss: 0.064159/157, train_loss: 0.087860/157, train_loss: 0.060761/157, train_loss: 0.064962/157, train_loss: 0.066263/157, train_loss: 0.057564/157, train_loss: 0.059165/157, train_loss: 0.069766/157, train_loss: 0.064067/157, train_loss: 0.067868/157, train_loss: 0.068069/157, train_loss: 0.068570/157, train_loss: 0.063071/157, train_loss: 0.075072/157, train_loss: 0.057573/157, train_loss: 0.070374/157, train_loss: 0.046975/157, train_loss: 0.048676/157, train_loss: 0.064377/157, train_loss: 0.066578/157, train_loss: 0.068179/157, train_loss: 0.041180/157, train_loss: 0.063981/157, train_loss: 0.064482/157, train_loss: 0.061983/157, train_loss: 0.071384/157, train_loss: 0.046885/157, train_loss: 0.082286/157, train_loss: 0.054387/157, train_loss: 0.063388/157, train_loss: 0.061489/157, train_loss: 0.056190/157, train_loss: 0.061291/157, train_loss: 0.045992/157, train_loss: 0.055193/157, train_loss: 0.057394/157, train_loss: 0.061695/157, train_loss: 0.058196/157, train_loss: 0.057697/157, train_loss: 0.070898/157, train_loss: 0.052099/157, train_loss: 0.0504100/157, train_loss: 0.0614101/157, train_loss: 0.0548102/157, train_loss: 0.0600103/157, train_loss: 0.0431104/157, train_loss: 0.0687105/157, train_loss: 0.0390106/157, train_loss: 0.0598107/157, train_loss: 0.0742108/157, train_loss: 0.0395109/157, train_loss: 0.0509110/157, train_loss: 0.0751111/157, train_loss: 0.0609112/157, train_loss: 0.0521113/157, train_loss: 0.0465114/157, train_loss: 0.0432115/157, train_loss: 0.0612116/157, train_loss: 0.0568117/157, train_loss: 0.0710118/157, train_loss: 0.0559119/157, train_loss: 0.0505120/157, train_loss: 0.0510121/157, train_loss: 0.0498122/157, train_loss: 0.0557123/157, train_loss: 0.0386124/157, train_loss: 0.0586125/157, train_loss: 0.0423126/157, train_loss: 0.0433127/157, train_loss: 0.0770128/157, train_loss: 0.0465129/157, train_loss: 0.0621130/157, train_loss: 0.0510131/157, train_loss: 0.0534132/157, train_loss: 0.0546133/157, train_loss: 0.0647134/157, train_loss: 0.0577135/157, train_loss: 0.0550136/157, train_loss: 0.0396137/157, train_loss: 0.0409138/157, train_loss: 0.0565139/157, train_loss: 0.0600140/157, train_loss: 0.0376141/157, train_loss: 0.0658142/157, train_loss: 0.0392143/157, train_loss: 0.0607144/157, train_loss: 0.0524145/157, train_loss: 0.0482146/157, train_loss: 0.0600147/157, train_loss: 0.0695148/157, train_loss: 0.0483149/157, train_loss: 0.0417150/157, train_loss: 0.0529151/157, train_loss: 0.0595152/157, train_loss: 0.0427153/157, train_loss: 0.0392154/157, train_loss: 0.0445155/157, train_loss: 0.0412156/157, train_loss: 0.0796157/157, train_loss: 0.0418158/157, train_loss: 0.0538epoch 3 average loss: 0.0647saved new best metric modelcurrent epoch: 3 current AUC: 1.0000 current accuracy: 0.9917 best AUC: 1.0000 at epoch: 3----------epoch 4/41/157, train_loss: 0.03002/157, train_loss: 0.03683/157, train_loss: 0.03874/157, train_loss: 0.04945/157, train_loss: 0.03486/157, train_loss: 0.05197/157, train_loss: 0.04538/157, train_loss: 0.03389/157, train_loss: 0.055610/157, train_loss: 0.054611/157, train_loss: 0.049912/157, train_loss: 0.027213/157, train_loss: 0.039814/157, train_loss: 0.044115/157, train_loss: 0.049816/157, train_loss: 0.042217/157, train_loss: 0.033818/157, train_loss: 0.075019/157, train_loss: 0.050820/157, train_loss: 0.058321/157, train_loss: 0.042522/157, train_loss: 0.045623/157, train_loss: 0.042124/157, train_loss: 0.057125/157, train_loss: 0.047726/157, train_loss: 0.062527/157, train_loss: 0.054228/157, train_loss: 0.051929/157, train_loss: 0.042430/157, train_loss: 0.037831/157, train_loss: 0.038232/157, train_loss: 0.044133/157, train_loss: 0.039434/157, train_loss: 0.072435/157, train_loss: 0.030536/157, train_loss: 0.045237/157, train_loss: 0.051038/157, train_loss: 0.042639/157, train_loss: 0.037640/157, train_loss: 0.053641/157, train_loss: 0.039942/157, train_loss: 0.035443/157, train_loss: 0.047944/157, train_loss: 0.034945/157, train_loss: 0.050146/157, train_loss: 0.035547/157, train_loss: 0.052848/157, train_loss: 0.045749/157, train_loss: 0.045050/157, train_loss: 0.039151/157, train_loss: 0.042052/157, train_loss: 0.032753/157, train_loss: 0.050754/157, train_loss: 0.039155/157, train_loss: 0.045756/157, train_loss: 0.027457/157, train_loss: 0.042458/157, train_loss: 0.030259/157, train_loss: 0.043460/157, train_loss: 0.053161/157, train_loss: 0.037662/157, train_loss: 0.038463/157, train_loss: 0.038064/157, train_loss: 0.041165/157, train_loss: 0.028066/157, train_loss: 0.037967/157, train_loss: 0.034168/157, train_loss: 0.038569/157, train_loss: 0.031370/157, train_loss: 0.054071/157, train_loss: 0.030672/157, train_loss: 0.037873/157, train_loss: 0.032774/157, train_loss: 0.027075/157, train_loss: 0.043876/157, train_loss: 0.040977/157, train_loss: 0.037178/157, train_loss: 0.029679/157, train_loss: 0.037980/157, train_loss: 0.026281/157, train_loss: 0.041882/157, train_loss: 0.052883/157, train_loss: 0.022584/157, train_loss: 0.056485/157, train_loss: 0.039386/157, train_loss: 0.029887/157, train_loss: 0.027188/157, train_loss: 0.043589/157, train_loss: 0.054790/157, train_loss: 0.036091/157, train_loss: 0.039292/157, train_loss: 0.029393/157, train_loss: 0.060694/157, train_loss: 0.035095/157, train_loss: 0.028096/157, train_loss: 0.034797/157, train_loss: 0.041598/157, train_loss: 0.035699/157, train_loss: 0.0505100/157, train_loss: 0.0360101/157, train_loss: 0.0430102/157, train_loss: 0.0335103/157, train_loss: 0.0231104/157, train_loss: 0.0413105/157, train_loss: 0.0260106/157, train_loss: 0.0375107/157, train_loss: 0.0288108/157, train_loss: 0.0321109/157, train_loss: 0.0343110/157, train_loss: 0.0406111/157, train_loss: 0.0323112/157, train_loss: 0.0406113/157, train_loss: 0.0335114/157, train_loss: 0.0262115/157, train_loss: 0.0288116/157, train_loss: 0.0216117/157, train_loss: 0.0377118/157, train_loss: 0.0299119/157, train_loss: 0.0556120/157, train_loss: 0.0283121/157, train_loss: 0.0310122/157, train_loss: 0.0326123/157, train_loss: 0.0386124/157, train_loss: 0.0220125/157, train_loss: 0.0225126/157, train_loss: 0.0431127/157, train_loss: 0.0316128/157, train_loss: 0.0368129/157, train_loss: 0.0427130/157, train_loss: 0.0390131/157, train_loss: 0.0453132/157, train_loss: 0.0276133/157, train_loss: 0.0395134/157, train_loss: 0.0232135/157, train_loss: 0.0235136/157, train_loss: 0.0320137/157, train_loss: 0.0326138/157, train_loss: 0.0252139/157, train_loss: 0.0309140/157, train_loss: 0.0199141/157, train_loss: 0.0285142/157, train_loss: 0.0236143/157, train_loss: 0.0365144/157, train_loss: 0.0353145/157, train_loss: 0.0381146/157, train_loss: 0.0333147/157, train_loss: 0.0377148/157, train_loss: 0.0247149/157, train_loss: 0.0357150/157, train_loss: 0.0327151/157, train_loss: 0.0238152/157, train_loss: 0.0183153/157, train_loss: 0.0431154/157, train_loss: 0.0352155/157, train_loss: 0.0445156/157, train_loss: 0.0222157/157, train_loss: 0.0246158/157, train_loss: 0.0596epoch 4 average loss: 0.0386saved new best metric modelcurrent epoch: 4 current AUC: 1.0000 current accuracy: 0.9963 best AUC: 1.0000 at epoch: 4train completed, best_metric: 1.0000 at epoch: 4Plot the loss and metricplt.figure(\"train\", (12, 6))plt.subplot(1, 2, 1)plt.title(\"Epoch Average Loss\")x = [i + 1 for i in range(len(epoch_loss_values))]y = epoch_loss_valuesplt.xlabel(\"epoch\")plt.plot(x, y)plt.subplot(1, 2, 2)plt.title(\"Val AUC\")x = [val_interval * (i + 1) for i in range(len(metric_values))]y = metric_valuesplt.xlabel(\"epoch\")plt.plot(x, y)plt.show()Evaluate the model on test datasetAfter training and validation, we already got the best model on validation test.We need to evaluate the model on test dataset to check whether it’s robust and not over-fitting.We’ll use these predictions to generate a classification report.model.load_state_dict(torch.load( os.path.join(root_dir, \"best_metric_model.pth\")))model.eval()y_true = []y_pred = []with torch.no_grad(): for test_data in test_loader: test_images, test_labels = ( test_data[0].to(device), test_data[1].to(device), ) pred = model(test_images).argmax(dim=1) for i in range(len(pred)): y_true.append(test_labels[i].item()) y_pred.append(pred[i].item())print(classification_report( y_true, y_pred, target_names=class_names, digits=4)) precision recall f1-score support AbdomenCT 0.9919 0.9879 0.9899 995 BreastMRI 0.9977 0.9920 0.9949 880 CXR 1.0000 0.9949 0.9974 982 ChestCT 0.9931 1.0000 0.9966 1014 Hand 0.9952 0.9962 0.9957 1048 HeadCT 0.9929 0.9990 0.9959 976 accuracy 0.9951 5895 macro avg 0.9951 0.9950 0.9951 5895weighted avg 0.9951 0.9951 0.9951 5895Cleanup data directoryRemove directory if a temporary was used.if directory is None: shutil.rmtree(root_dir)GPU Utilization| 0 N/A N/A 2429330 C /opt/conda/bin/python3.8 3799MiB |+—————————————————————————–+Fri Sep 23 17:26:34 2022+—————————————————————————–+| NVIDIA-SMI 470.103.01 Driver Version: 470.103.01 CUDA Version: 11.4 ||——————————-+———————-+———————-+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 NVIDIA A100-SXM… On | 00000000:07:00.0 Off | 0 || N/A 39C P0 244W / 400W | 3802MiB / 81251MiB | 50% Default || | | Disabled |+——————————-+———————-+———————-+" }, { "title": " Reproducible Slurm Notebook", "url": "/posts/Reproducible-slurm-notebook/", "categories": "", "tags": "", "date": "2022-09-03 00:00:00 +0700", "snippet": "Reproducible SLURM jobs from a Jupyter NotebookFor Jupyter notebook and Python lover, we can start automating our workflows by creating notebooks containing any number of pre-processing steps, batch scripts, monitoring commands and post-processing steps to be performed during and after job execution.This can make HPC workflows more reproducible and shareable, and ready-made notebooks can make it easier, for example, for new reseacher students to get started.In this post, instead of manage jobs via SSH terminal or open on demand web portal, we demo how to use Slurm Magics to do the interactive analysis and Slurm job management without leaving from Jupyter Notebook.SLURM magics Slurm magic developed by National Energy Research Scientific Computing (NERSC)[1] The slurm magic command will interact with Slurm workload management, for short, it is Slurm command wrapper. Each command implement by fork or spawned new __subprocess then output is captured and show on notebook with UTF-8 decoding.Using SLURM magicsAssume, you connect to exascale.mahidol.ac.th portal, and create Jupyter Notebook server.In new jupyter notebook, we need to load IPython slurm extension:pip install git+https://github.com/NERSC/slurm-magic.git%load_ext slurm_magicFrom now on, we can interact with Slurm workload manager,without VPN SSH%lsmagic Available line magics:%alias %alias_magic %autoawait %autocall %automagic %autosave %bookmark %cat %cd %clear %colors %conda %config %connect_info %cp %debug %dhist %dirs %doctest_mode %ed %edit %env %gui %hist %history %killbgscripts %ldir %less %lf %lk %ll %load %load_ext %loadpy %logoff %logon %logstart %logstate %logstop %ls %lsmagic %lx %macro %magic %man %matplotlib %mkdir %more %mv %notebook %page %pastebin %pdb %pdef %pdoc %pfile %pinfo %pinfo2 %pip %popd %pprint %precision %prun %psearch %psource %pushd %pwd %pycat %pylab %qtconsole %quickref %recall %rehashx %reload_ext %rep %rerun %reset %reset_selective %rm %rmdir %run %sacct %sacctmgr %salloc %sattach %save %sbatch %sbcast %sc %scancel %scontrol %sdiag %set_env %sinfo %slurm %smap %sprio %squeue %sreport %srun %sshare %sstat %store %strigger %sview %sx %system %tb %time %timeit %unalias %unload_ext %who %who_ls %whos %xdel %xmodeAvailable cell magics:%%! %%HTML %%SVG %%bash %%capture %%debug %%file %%html %%javascript %%js %%latex %%markdown %%perl %%prun %%pypy %%python %%python2 %%python3 %%ruby %%sbatch %%script %%sh %%svg %%sx %%system %%time %%timeit %%writefileAutomagic is ON, % prefix IS NOT needed for line magics.import warningswarnings.filterwarnings('ignore')Submit GROMACS job and analysis results on the flyTo demo how to submit job for __ simulations of biological macromolecules__ GROMACS package example for Lysozyme[3] in water is used.!git clone https://github.com/snitgit/Slurm-jupyter-notebook.gitcd Slurm-jupyter-notebook//home/snit.san/slurm-magic/Slurm-jupyter-notebook%cd gromacs_job//home/snit.san/slurm-magic/Slurm-jupyter-notebook/gromacs_jobsinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST 0 batch* up 420-00:00: 1 mix omega 1 batch* up 420-00:00: 3 idle tensorcore,turing,zeta Use %sbatch to submit job on next cellsqueue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 0 6599 batch sys-dash snit.san R 1:13 1 omega 1 5890 batch bash tantip.a R 9-02:06:59 1 omega %%sbatch#!/bin/bash -l#SBATCH -A ict#SBATCH -N 1#SBATCH -t 01:05:00#SBATCH -J gromacs#SBATCH --gres=gpu:2#SBATCH -w, --nodelist=zeta# change temp or log to your folderexport SINGULARITY_TMPDIR=/home/snit.san/tmpexport CUDA_MPS_LOG_DIRECTORY=/home/snit.san/var/log/mvidia-mpsmodule use /shared/software/software/mulabsmodule load hpcx-ompimodule load gromacsgmx grompp -f npt.mdp -c start.gro -p topol.top -maxwarn 100gmx mdrun -ntmpi 1 -ntomp 40 -v -pin on -nb gpu --pme gpu -noconfout -s topol.tpr -deffnm npt'Submitted batch job 6611\\n'%squeue -u snit.san JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 0 6599 batch sys-dash snit.san R 44:26 1 omega 1 6611 batch gromacs snit.san R 0:03 1 zeta Gromacs utility can be used to extract information from the binary output files.To run it, we write shell commands into a code cell containing the %%bash magic to let Jupyter execute a bash script. In our case, we extract time-dependent values of temperature, density and pressure from the simulation[4].%%bashmodule use /shared/software/software/mulabsmodule load gromacs/2021echo \"Temperature\" | gmx energy -f npt.edr -o temperature.xvgecho \"Density\" | gmx energy -f npt.edr -o density.xvgecho \"Pressure\" | gmx energy -f npt.edr -o pressure.xvgStatistics over 161501 steps [ 0.0000 through 323.0000 ps ], 1 data setsAll statistics are over 16151 pointsEnergy Average Err.Est. RMSD Tot-Drift-------------------------------------------------------------------------------Temperature 300.024 0.069 1.66438 0.354538 (K)Statistics over 162501 steps [ 0.0000 through 325.0000 ps ], 1 data setsAll statistics are over 16251 pointsEnergy Average Err.Est. RMSD Tot-Drift-------------------------------------------------------------------------------Density 1016.21 0.21 2.37206 -0.433522 (kg/m^3)Statistics over 163501 steps [ 0.0000 through 327.0000 ps ], 1 data setsAll statistics are over 16351 pointsEnergy Average Err.Est. RMSD Tot-Drift-------------------------------------------------------------------------------Pressure 1.06924 0.18 140.482 0.193272 (bar)INFO: Using cached SIF image :-) GROMACS - gmx energy, 2021-dev-20210128-6a0b0c4-dirty-unknown (-: GROMACS is written by: Andrey Alekseenko Emile Apol Rossen Apostolov Paul Bauer Herman J.C. Berendsen Par Bjelkmar Christian Blau Viacheslav Bolnykh Kevin Boyd Aldert van Buuren Rudi van Drunen Anton Feenstra Gilles Gouaillardet Alan Gray Gerrit Groenhof Anca Hamuraru Vincent Hindriksen M. Eric Irrgang Aleksei Iupinov Christoph Junghans Joe Jordan Dimitrios Karkoulis Peter Kasson Jiri Kraus Carsten Kutzner Per Larsson Justin A. Lemkul Viveca Lindahl Magnus Lundborg Erik Marklund Pascal Merz Pieter Meulenhoff Teemu Murtola Szilard Pall Sander Pronk Roland Schulz Michael Shirts Alexey Shvetsov Alfons Sijbers Peter Tieleman Jon Vincent Teemu Virolainen Christian Wennberg Maarten Wolf Artem Zhmurov and the project leaders: Mark Abraham, Berk Hess, Erik Lindahl, and David van der SpoelCopyright (c) 1991-2000, University of Groningen, The Netherlands.Copyright (c) 2001-2019, The GROMACS development team atUppsala University, Stockholm University andthe Royal Institute of Technology, Sweden.check out http://www.gromacs.org for more information.GROMACS is free software; you can redistribute it and/or modify itunder the terms of the GNU Lesser General Public Licenseas published by the Free Software Foundation; either version 2.1of the License, or (at your option) any later version.GROMACS: gmx energy, version 2021-dev-20210128-6a0b0c4-dirty-unknownExecutable: /usr/local/gromacs/avx2_256/bin/gmxData prefix: /usr/local/gromacs/avx2_256Working dir: /home/snit.san/slurm-magic/Slurm-jupyter-notebook/gromacs_jobCommand line: gmx energy -f npt.edr -o temperature.xvgOpened npt.edr as single precision energy fileSelect the terms you want from the following list byselecting either (part of) the name or the number or a combination.End your selection with an empty line or a zero.------------------------------------------------------------------- 1 Bond 2 Angle 3 Proper-Dih. 4 Ryckaert-Bell. 5 LJ-14 6 Coulomb-14 7 LJ-(SR) 8 Disper.-corr. 9 Coulomb-(SR) 10 Coul.-recip. 11 Potential 12 Kinetic-En. 13 Total-Energy 14 Conserved-En. 15 Temperature 16 Pres.-DC 17 Pressure 18 Constr.-rmsd 19 Box-X 20 Box-Y 21 Box-Z 22 Volume 23 Density 24 pV 25 Enthalpy 26 Vir-XX 27 Vir-XY 28 Vir-XZ 29 Vir-YX 30 Vir-YY 31 Vir-YZ 32 Vir-ZX 33 Vir-ZY 34 Vir-ZZ 35 Pres-XX 36 Pres-XY 37 Pres-XZ 38 Pres-YX 39 Pres-YY 40 Pres-YZ 41 Pres-ZX 42 Pres-ZY 43 Pres-ZZ 44 #Surf*SurfTen 45 Box-Vel-XX 46 Box-Vel-YY 47 Box-Vel-ZZ 48 T-Protein 49 T-non-Protein 50 Lamb-Protein 51 Lamb-non-Protein Back Off! I just backed up temperature.xvg to ./#temperature.xvg.2#Last energy frame read 323 time 323.000 GROMACS reminds you: \"Der Ball ist rund, das Spiel dauert 90 minuten, alles andere ist Theorie\" (Lola rennt)INFO: Using cached SIF image :-) GROMACS - gmx energy, 2021-dev-20210128-6a0b0c4-dirty-unknown (-: GROMACS is written by: Andrey Alekseenko Emile Apol Rossen Apostolov Paul Bauer Herman J.C. Berendsen Par Bjelkmar Christian Blau Viacheslav Bolnykh Kevin Boyd Aldert van Buuren Rudi van Drunen Anton Feenstra Gilles Gouaillardet Alan Gray Gerrit Groenhof Anca Hamuraru Vincent Hindriksen M. Eric Irrgang Aleksei Iupinov Christoph Junghans Joe Jordan Dimitrios Karkoulis Peter Kasson Jiri Kraus Carsten Kutzner Per Larsson Justin A. Lemkul Viveca Lindahl Magnus Lundborg Erik Marklund Pascal Merz Pieter Meulenhoff Teemu Murtola Szilard Pall Sander Pronk Roland Schulz Michael Shirts Alexey Shvetsov Alfons Sijbers Peter Tieleman Jon Vincent Teemu Virolainen Christian Wennberg Maarten Wolf Artem Zhmurov and the project leaders: Mark Abraham, Berk Hess, Erik Lindahl, and David van der SpoelCopyright (c) 1991-2000, University of Groningen, The Netherlands.Copyright (c) 2001-2019, The GROMACS development team atUppsala University, Stockholm University andthe Royal Institute of Technology, Sweden.check out http://www.gromacs.org for more information.GROMACS is free software; you can redistribute it and/or modify itunder the terms of the GNU Lesser General Public Licenseas published by the Free Software Foundation; either version 2.1of the License, or (at your option) any later version.GROMACS: gmx energy, version 2021-dev-20210128-6a0b0c4-dirty-unknownExecutable: /usr/local/gromacs/avx2_256/bin/gmxData prefix: /usr/local/gromacs/avx2_256Working dir: /home/snit.san/slurm-magic/Slurm-jupyter-notebook/gromacs_jobCommand line: gmx energy -f npt.edr -o density.xvgOpened npt.edr as single precision energy fileSelect the terms you want from the following list byselecting either (part of) the name or the number or a combination.End your selection with an empty line or a zero.------------------------------------------------------------------- 1 Bond 2 Angle 3 Proper-Dih. 4 Ryckaert-Bell. 5 LJ-14 6 Coulomb-14 7 LJ-(SR) 8 Disper.-corr. 9 Coulomb-(SR) 10 Coul.-recip. 11 Potential 12 Kinetic-En. 13 Total-Energy 14 Conserved-En. 15 Temperature 16 Pres.-DC 17 Pressure 18 Constr.-rmsd 19 Box-X 20 Box-Y 21 Box-Z 22 Volume 23 Density 24 pV 25 Enthalpy 26 Vir-XX 27 Vir-XY 28 Vir-XZ 29 Vir-YX 30 Vir-YY 31 Vir-YZ 32 Vir-ZX 33 Vir-ZY 34 Vir-ZZ 35 Pres-XX 36 Pres-XY 37 Pres-XZ 38 Pres-YX 39 Pres-YY 40 Pres-YZ 41 Pres-ZX 42 Pres-ZY 43 Pres-ZZ 44 #Surf*SurfTen 45 Box-Vel-XX 46 Box-Vel-YY 47 Box-Vel-ZZ 48 T-Protein 49 T-non-Protein 50 Lamb-Protein 51 Lamb-non-Protein Back Off! I just backed up density.xvg to ./#density.xvg.2#Last energy frame read 325 time 325.000 GROMACS reminds you: \"It's Calling Me to Break my Bonds, Again...\" (Van der Graaf)INFO: Using cached SIF image :-) GROMACS - gmx energy, 2021-dev-20210128-6a0b0c4-dirty-unknown (-: GROMACS is written by: Andrey Alekseenko Emile Apol Rossen Apostolov Paul Bauer Herman J.C. Berendsen Par Bjelkmar Christian Blau Viacheslav Bolnykh Kevin Boyd Aldert van Buuren Rudi van Drunen Anton Feenstra Gilles Gouaillardet Alan Gray Gerrit Groenhof Anca Hamuraru Vincent Hindriksen M. Eric Irrgang Aleksei Iupinov Christoph Junghans Joe Jordan Dimitrios Karkoulis Peter Kasson Jiri Kraus Carsten Kutzner Per Larsson Justin A. Lemkul Viveca Lindahl Magnus Lundborg Erik Marklund Pascal Merz Pieter Meulenhoff Teemu Murtola Szilard Pall Sander Pronk Roland Schulz Michael Shirts Alexey Shvetsov Alfons Sijbers Peter Tieleman Jon Vincent Teemu Virolainen Christian Wennberg Maarten Wolf Artem Zhmurov and the project leaders: Mark Abraham, Berk Hess, Erik Lindahl, and David van der SpoelCopyright (c) 1991-2000, University of Groningen, The Netherlands.Copyright (c) 2001-2019, The GROMACS development team atUppsala University, Stockholm University andthe Royal Institute of Technology, Sweden.check out http://www.gromacs.org for more information.GROMACS is free software; you can redistribute it and/or modify itunder the terms of the GNU Lesser General Public Licenseas published by the Free Software Foundation; either version 2.1of the License, or (at your option) any later version.GROMACS: gmx energy, version 2021-dev-20210128-6a0b0c4-dirty-unknownExecutable: /usr/local/gromacs/avx2_256/bin/gmxData prefix: /usr/local/gromacs/avx2_256Working dir: /home/snit.san/slurm-magic/Slurm-jupyter-notebook/gromacs_jobCommand line: gmx energy -f npt.edr -o pressure.xvgOpened npt.edr as single precision energy fileSelect the terms you want from the following list byselecting either (part of) the name or the number or a combination.End your selection with an empty line or a zero.------------------------------------------------------------------- 1 Bond 2 Angle 3 Proper-Dih. 4 Ryckaert-Bell. 5 LJ-14 6 Coulomb-14 7 LJ-(SR) 8 Disper.-corr. 9 Coulomb-(SR) 10 Coul.-recip. 11 Potential 12 Kinetic-En. 13 Total-Energy 14 Conserved-En. 15 Temperature 16 Pres.-DC 17 Pressure 18 Constr.-rmsd 19 Box-X 20 Box-Y 21 Box-Z 22 Volume 23 Density 24 pV 25 Enthalpy 26 Vir-XX 27 Vir-XY 28 Vir-XZ 29 Vir-YX 30 Vir-YY 31 Vir-YZ 32 Vir-ZX 33 Vir-ZY 34 Vir-ZZ 35 Pres-XX 36 Pres-XY 37 Pres-XZ 38 Pres-YX 39 Pres-YY 40 Pres-YZ 41 Pres-ZX 42 Pres-ZY 43 Pres-ZZ 44 #Surf*SurfTen 45 Box-Vel-XX 46 Box-Vel-YY 47 Box-Vel-ZZ 48 T-Protein 49 T-non-Protein 50 Lamb-Protein 51 Lamb-non-Protein Back Off! I just backed up pressure.xvg to ./#pressure.xvg.2#Last energy frame read 327 time 327.000 GROMACS reminds you: \"If you want to destroy my sweater, hold this thread as I walk away.\" (Weezer)define a function to extract data from the processed Gromacs xvg filesdef get_prop(prop): \"\"\"Extract system property (Temperature, Pressure, Potential, or Density) from a GROMACS xvg file. Returns lists of time and property.\"\"\" x = [] y = [] f_prop = open(\"%s.xvg\" % prop, 'r') for line in f_prop: if line[0] == '#' or line[0] == '@': continue content = line.split() x.append(float(content[0])) y.append(float(content[1])) f_prop.close() return x,yHaving got data column from gromacs, we shoud diplay graph on Notebook using matplotlib.import matplotlib.pyplot as plt%matplotlib inlinetime,dens = get_prop(\"density\")plt.plot(time,dens)plt.xlabel('Simulation time [ps]')plt.ylabel('Density [kg/m$^3$]')plt.plot(time,dens)time,pres = get_prop(\"pressure\")plt.plot(time,pres)[&lt;matplotlib.lines.Line2D at 0x7f3e490ecfd0&gt;]plt.plot(dens,pres[:len(dens)],'b+')[&lt;matplotlib.lines.Line2D at 0x7f3e49066dc0&gt;]References: 1. Slurm-magin https://github.com/NERSC/slurm-magic 2. Using Jupyter Notebooks to manage SLURM jobs https://www.kth.se/blogs/pdc/2019/01/using-jupyter-notebooks-to-manage-slurm-jobs/3. GROMACS tutorialhttp://www.mdtutorials.com/gmx/lysozyme/index.html 4. Using Jupyter Notebooks to manage SLURM jobshttps://www.kth.se/blogs/pdc/2019/01/using-jupyter-notebooks-to-manage-slurm-jobs/" }, { "title": "Quantum ESPRESSO on exascale.mahidol.ac.th Multi-Node-Multi-GPUs MNMG Testing", "url": "/posts/Quantum-Exspesso/", "categories": "Physics, Chemistry", "tags": "", "date": "2022-06-27 04:40:29 +0700", "snippet": "Quantum ESPRESSO is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale based on density-functional theory, plane waves, and pseudopotentials.What can PWscf do ?PWscf performs many different kinds of self-consistent calculations of electronic-structure properties within Density-Functional Theory (DFT), using a Plane-Wave (PW) basis set and pseudopotentials (PP).[1]In particular: ground-state energy and one-electron (Kohn-Sham) orbitals, atomic forces, stresses; structural optimization, also with variable cell; molecular dynamics on the Born-Oppenheimer surface, also with variable cell; macroscopic polarization (and orbital magnetization) via Berry Phases; various forms of finite electric fields, with a sawtooth potential or with the modern theory of polarization; Effective Screening Medium (ESM) method Download Dataset:The environment variable BENCHMARK_DIR will be used throughout the example to refer to the directory containing the AUSURF112 input files.cd ~mdkir qemkdir qe/ausurfcd qe/ausurfwget https://repository.prace-ri.eu/git/UEABS/ueabs/-/raw/master/quantum_espresso/test_cases/small/Au.pbe-nd-van.UPFwget https://repository.prace-ri.eu/git/UEABS/ueabs/-/raw/master/quantum_espresso/test_cases/small/ausurf.inRun QE on One Compute Node One GPUAs suggestion rules for runing on GPU QE on HPC and GPU systems: 1 GPU : 1 MPI Fill the CPU with OpenMP threads No task groups (-ntg 1) No parallel eigensolver (-ndiag 1), no diagonized?$ cd ~/qe/ausurf$ module unload *$ module load quantum_espresso/v7.0$ mpirun -n 1 pw.x -npool 1 -ntg 1 -ndiag 1 -input ausurf.in Time to finish job is 3 minutes.Run QE on One Compute Node 4 GPUsWe need to bind UCX/OMPI with script from give URL.One important component behind the script is Nvidia Multi-Process-Service or MPS.NVIDIA MPS improves the parallel performance by allowing multiple process to instantaneously share GPU compute resources.Figure: Nvidia Tranditional: Full process isolationFigure: Nvidia MPS: Full process isolationSource: https://www.olcf.ornl.gov/wp-content/uploads/2021/06/MPS_ORNL_20210817.pdf$ cd ~/qe/ausurf$ wget $ wget https://raw.githubusercontent.com/LStuber/binding/master/binder.sh $ module unload *$ module load quantum_espresso/v7.0$ mpirun -n 4 binder.sh pw.x -input ausurf.in -npool 4Time to finish job is 2 minutes.Run QE on Multi-Nodes ?Later comming soon…References: MaX school on Advanced Materials and Molecular Modelling with Quantum ESPRESSO," }, { "title": "Simplify Exascale Workflows with Singularity Container and Environment Modules", "url": "/posts/Integrate-Container-Environment-Module/", "categories": "singularity, module", "tags": "", "date": "2022-06-26 04:21:29 +0700", "snippet": "Before container based software has been developemented, HPC or High Performance Computing system, administrators use to compile application manually solving libary dependency issues and config applications with environment module. User can load part of softwares as they are only needed. The advantages of environment modules are that they allow you to load and unload software configurations dynamically in a clean fashion, providing end users with the best experience when it comes to customizing a specific configuration for each application.$ module avail$ module load gromacs$ gmx ...However, wildly satifying user needs for distributed system, HPC and AI applications, complex library dependenies is nighmare for administor. HPC administrators are often overwhelmed with the amount of time they must spend to install, upgrade, and monitor software. HPC system is slowly upgraded system in user point view for HPC. So organization to Public HPC public cloud.Docker or Singularity container can be a great way to simplify the overall development and deployment process, or DevOps. DockerHub, public share dockerfile and NVIDIA Container NGC provide hurge pre-compile and pre-configure for HPC user. If some journal paper provide paper with code which is usaully come with container to repeat the resarch results. In this post, we motivate you to apply NVIDIA NGC Container with Environment Modules, which jointed together to make our process faster and more easier.Why containers? Allow you to package a software application, libraries, and other runtime dependencies into a single image Eliminate the need to install complex software environments Enable you to pull and run applications on the system without any assistance from system administrators Allow researchers to share their application with other researchers for corroborationSource: https://developer.nvidia.com/blog/simplifying-hpc-workflows-with-ngc-container-environment-modules/Container as ModulesThe past few years, we have seen containers become quite popular when it comes to deploying HPC applications,such as BioContainers. However, most super computing center and users submit job or running application using environment modules. Use familiar environment module commands, ensuring a minimal learning curve or change to existing workflows Make use of all the benefits of containers, including and reproducibility Leverage all of the optimized HPC and Deep Learning containers from Docker Hub, NVIDIA Container Following step is initial process that setup only time first time.OutlineGuide from ngc-container-environment$ ssh username@aim1.mahidol.ac.th$ salloc -w some_compute_node$ ssh username@some_compute_node$ git clone https://github.com/NVIDIA/ngc-container-environment-modules$ module use $(pwd)/ngc-container-environment-modules$ module load gromacs$ gmxThe last two steps are runing jobs. The gmx command on the host is linked to the GROMACS container. Singularity mounts $HOME,/tmp and $(PWD) by default.Custmize Configure for Exascale ClusterThe NGC container environment modules are a reference. It is expected that they will need some modification for Exascale cluster. The name of the Singularity module. The container environment modules try to load the Singularity module (note theb capital ‘S’). Set the NGC_SINGULARITY_MODULE environment variable set it to none. Singularity uses a temporary directory to build the squashfs filesystem, and this temp space needs to be large enough to hold the entire resulting Singularity image. By default this happens in /tmp but the location can be configured by setting SINGULARITY_TMPDIR $ echo '# Setup Singularity and Module work together' &gt;&gt; ~/.bashrc$ echo 'export SINGULARITY_TMPDIR=\"/home/snit.san/tmp\"' &gt;&gt; ~/.bashrc$ echo 'export NGC_SINGULARITY_MODULE=none' &gt;&gt; ~/.bashrc$ echo 'module use /home/snit.san/ngc-container-environment-modules' &gt;&gt; ~/.bashrc$ echo 'export SINGULARITY_TMPDIR=/home/snit.san/tmp' &gt;&gt; ~/.bashrcExamplesBasic : One Node Multi GPUsDownload a GROMACS benchmark to run this exmaple.$ wget https://ftp.gromacs.org/pub/benchmarks/water_GMX50_bare.tar.gz$ tar xvfz water_GMX50_bare.tar.gz$ salloc -w turing$ ssh turing$ cd /home/snit.san/GROMACS/water-cut1.0_GMX50_bare/1536$ module load gromacs/2020.2$ gmx mdrun -ntmpi 1 -ntomp 40 -v -pin on -nb gpu --pme gpu --resetstep 12000 -nsteps 20000 -nstlist 400 -noconfout -s topol.tprInteractive : Deep Learningg with PyTorch$ salloc -w zeta$ ssh zeta$ module load pytorch/20.06-py3$ python3&gt;&gt;&gt; import torch&gt;&gt;&gt; x = torch.randn(3, 7)&gt;&gt;&gt; xtensor([[-0.5307, 0.8221, -0.8459, 0.7091, -0.7165, 0.6743, 1.8597], [ 0.0961, 0.3864, 0.6767, -1.4271, 1.4069, -0.4359, -2.3566], [-0.4707, -1.0400, 0.2112, -0.3847, -1.6868, 0.4977, -0.1213]])&gt;&gt;&gt;Jupyter notebooks: cuSignal possible with Rapids project$ salloc -w turing$ ssh turing$ module load rapidsai$ jupyter notebook --ip 0.0.0.0 --no-browser --notebook-dir /rapids/notebooksMulti Node Multi GPUs: MNMG with Kokkos and MPIDownload the LAMMPS Molecular Dynamics Simulator, Lennard Jones fluid dataset to run this example.$ mkdir LAMMPS_test$ cd LAMMPS_test$ wget https://www.lammps.org/inputs/in.lj.txt$ module load lammps/15Jun2020$ mpirun -n 2 lmp -in in.lj.txt -var x 8 -var y 8 -var z 8 -k on g 2 -sf kk -pk kokkos cuda/aware on neigh full comm device binsize 2.8" } ]
